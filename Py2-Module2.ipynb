{"cells":[{"cell_type":"markdown","source":["## Module 2\n\nCreating Datasets, organising raw data and working with structured APIs"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e96b9521-8e37-4ca8-b50a-a8fddcde253c"}}},{"cell_type":"markdown","source":["This file is running on Databricks cluster: **DBR 9.1 LTS | Spark 3.1.2 | Scala 2.12**\n\nNotebook has default language: **Python**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"67d1719f-ace8-4dee-8bd9-29c3dd9a8785"}}},{"cell_type":"markdown","source":["## Reading data  with PySpark and SparkR and Scala"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d3ea9e98-cb35-4e18-a677-7ef469b986e2"}}},{"cell_type":"markdown","source":["We will create a Spark Session for easier manipulation with RDD files using **PySpark**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b0f0d76c-a935-4d68-9530-0b3854071094"}}},{"cell_type":"code","source":["from pyspark.sql import SparkSession"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7dad2b23-73f7-4b9e-a3f8-a075c55d1d27"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark = SparkSession \\\n    .builder \\\n    .appName(\"Module 2 with Python\") \\\n    .getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"83d610f3-d73b-44da-b756-262f021412f0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# spark is an existing SparkSession\ndf = spark.read.json(\"dbfs:/FileStore/module2/json2_1.json\")\n\n# Displays the content of the DataFrame to stdout\ndf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eecf8fbf-0caa-4bc8-a922-266b6ac4bf22"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+------+----+------+-------+\n|Height| age|gender|   name|\n+------+----+------+-------+\n|  null|  59|  null|  Eddie|\n|   195|null|  null|Michael|\n|  null|  30|  null|   Andy|\n|  null|  19|  male| Justin|\n|  null|   8|  male|    Tom|\n|  null|  10|Female|    Ann|\n|   175|  44|Female|Hillary|\n|  null|  41|  male|   Mike|\n+------+----+------+-------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+----+------+-------+\nHeight| age|gender|   name|\n+------+----+------+-------+\n  null|  59|  null|  Eddie|\n   195|null|  null|Michael|\n  null|  30|  null|   Andy|\n  null|  19|  male| Justin|\n  null|   8|  male|    Tom|\n  null|  10|Female|    Ann|\n   175|  44|Female|Hillary|\n  null|  41|  male|   Mike|\n+------+----+------+-------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Some DataFrame operations using **PySpark**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2dd84d5f-418f-461e-9bf3-062c67e191bf"}}},{"cell_type":"code","source":["# Print the schema in a tree format\ndf.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"50366a9b-ab83-4d28-8ee2-016015f8f625"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- Height: long (nullable = true)\n |-- age: long (nullable = true)\n |-- gender: string (nullable = true)\n |-- name: string (nullable = true)\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- Height: long (nullable = true)\n-- age: long (nullable = true)\n-- gender: string (nullable = true)\n-- name: string (nullable = true)\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Select only the \"name\" column\ndf.select(\"gender\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8bfcb547-f8b5-43a8-adf4-28d835d54fa0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+------+\n|gender|\n+------+\n|  null|\n|  null|\n|  null|\n|  male|\n|  male|\n|Female|\n|Female|\n|  male|\n+------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+\ngender|\n+------+\n  null|\n  null|\n  null|\n  male|\n  male|\nFemale|\nFemale|\n  male|\n+------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Select everybody, but increment the age by 1\n# And also creating the select list\ndf.select(df['name'],df['gender'], df['age'] + 1).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d369590f-5b7f-4145-9ab9-6da9ca9e89b9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-------+------+---------+\n|   name|gender|(age + 1)|\n+-------+------+---------+\n|  Eddie|  null|       60|\n|Michael|  null|     null|\n|   Andy|  null|       31|\n| Justin|  male|       20|\n|    Tom|  male|        9|\n|    Ann|Female|       11|\n|Hillary|Female|       45|\n|   Mike|  male|       42|\n+-------+------+---------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+------+---------+\n   name|gender|(age + 1)|\n+-------+------+---------+\n  Eddie|  null|       60|\nMichael|  null|     null|\n   Andy|  null|       31|\n Justin|  male|       20|\n    Tom|  male|        9|\n    Ann|Female|       11|\nHillary|Female|       45|\n   Mike|  male|       42|\n+-------+------+---------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Row filtering: Select people older than 21\ndf.filter(df['age'] > 21).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c4af6f35-d011-4cd6-b17b-061341e209e6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+------+---+------+-------+\n|Height|age|gender|   name|\n+------+---+------+-------+\n|  null| 59|  null|  Eddie|\n|  null| 30|  null|   Andy|\n|   175| 44|Female|Hillary|\n|  null| 41|  male|   Mike|\n+------+---+------+-------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+---+------+-------+\nHeight|age|gender|   name|\n+------+---+------+-------+\n  null| 59|  null|  Eddie|\n  null| 30|  null|   Andy|\n   175| 44|Female|Hillary|\n  null| 41|  male|   Mike|\n+------+---+------+-------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Row filtering: Select people between 7 and 31\ndf.filter((df['age'] > 7) & (df['age'] <= 31)).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"609ca48b-23e7-43b5-ac1c-d1dc3ca95bf3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+------+---+------+------+\n|Height|age|gender|  name|\n+------+---+------+------+\n|  null| 30|  null|  Andy|\n|  null| 19|  male|Justin|\n|  null|  8|  male|   Tom|\n|  null| 10|Female|   Ann|\n+------+---+------+------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+---+------+------+\nHeight|age|gender|  name|\n+------+---+------+------+\n  null| 30|  null|  Andy|\n  null| 19|  male|Justin|\n  null|  8|  male|   Tom|\n  null| 10|Female|   Ann|\n+------+---+------+------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Count people by age\ndf.groupBy(\"age\").count().show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e74dfcda-0a34-4d69-8beb-ded1fd069321"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----+-----+\n| age|count|\n+----+-----+\n|  19|    1|\n|null|    1|\n|  41|    1|\n|  10|    1|\n|  44|    1|\n|   8|    1|\n|  59|    1|\n|  30|    1|\n+----+-----+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+-----+\n age|count|\n+----+-----+\n  19|    1|\nnull|    1|\n  41|    1|\n  10|    1|\n  44|    1|\n   8|    1|\n  59|    1|\n  30|    1|\n+----+-----+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Some DataFrame operations using **SparkR**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"92cc77b7-77e6-43c4-ad34-9e257433c628"}}},{"cell_type":"code","source":["%r\nlibrary(SparkR)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"04cdaafb-907d-4c3f-bc1e-135abe56fc93"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>\n</pre>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>\n</pre>"]}}],"execution_count":0},{"cell_type":"code","source":["%r\nsparkR.session(appName = \"Module 2 with R\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5b78a39e-fc39-4f25-8aa5-f0e72d61294d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>Java ref type org.apache.spark.sql.SparkSession id 1 \n\n</pre>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>Java ref type org.apache.spark.sql.SparkSession id 1 \n\n</pre>"]}}],"execution_count":0},{"cell_type":"code","source":["%r\n\ndf <- read.json(\"dbfs:/FileStore/module2/json2_1.json\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5f7a364d-a57a-4f9a-a709-81a81f916643"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>\n</pre>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>\n</pre>"]}}],"execution_count":0},{"cell_type":"code","source":["%r\nhead(df,4)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"83909dd8-0b73-4a2a-9db4-958174538090"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>  Height age gender    name\n1     NA  59   &lt;NA&gt;   Eddie\n2    195  NA   &lt;NA&gt; Michael\n3     NA  30   &lt;NA&gt;    Andy\n4     NA  19   male  Justin\n\n</pre>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>  Height age gender    name\n1     NA  59   &lt;NA&gt;   Eddie\n2    195  NA   &lt;NA&gt; Michael\n3     NA  30   &lt;NA&gt;    Andy\n4     NA  19   male  Justin\n\n</pre>"]}}],"execution_count":0},{"cell_type":"code","source":["%r\nshowDF(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a1efa872-c7ca-4f48-9f1e-ba74c7822e43"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>+------+----+------+-------+\n|Height| age|gender|   name|\n+------+----+------+-------+\n|  null|  59|  null|  Eddie|\n|   195|null|  null|Michael|\n|  null|  30|  null|   Andy|\n|  null|  19|  male| Justin|\n|  null|   8|  male|    Tom|\n|  null|  10|Female|    Ann|\n|   175|  44|Female|Hillary|\n|  null|  41|  male|   Mike|\n+------+----+------+-------+\n\n</pre>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>+------+----+------+-------+\nHeight| age|gender|   name|\n+------+----+------+-------+\n  null|  59|  null|  Eddie|\n   195|null|  null|Michael|\n  null|  30|  null|   Andy|\n  null|  19|  male| Justin|\n  null|   8|  male|    Tom|\n  null|  10|Female|    Ann|\n   175|  44|Female|Hillary|\n  null|  41|  male|   Mike|\n+------+----+------+-------+\n\n</pre>"]}}],"execution_count":0},{"cell_type":"code","source":["%r\n\n# Print the schema in a tree format\nprintSchema(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4c8674e1-c04f-4acc-ad92-9ab37edaa088"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>root\n |-- Height: long (nullable = true)\n |-- age: long (nullable = true)\n |-- gender: string (nullable = true)\n |-- name: string (nullable = true)\n\n</pre>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>root\n-- Height: long (nullable = true)\n-- age: long (nullable = true)\n-- gender: string (nullable = true)\n-- name: string (nullable = true)\n\n</pre>"]}}],"execution_count":0},{"cell_type":"code","source":["%r\n\n# Select only the \"name\" column\nhead(select(df, \"name\"))\n "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fdfee5e7-1e07-4131-89e0-39a344abad22"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>     name\n1   Eddie\n2 Michael\n3    Andy\n4  Justin\n5     Tom\n6     Ann\n\n</pre>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>     name\n1   Eddie\n2 Michael\n3    Andy\n4  Justin\n5     Tom\n6     Ann\n\n</pre>"]}}],"execution_count":0},{"cell_type":"code","source":["\n%r\n\n# Select everybody, but increment the age by 1\nhead(select(df, df$name, df$age + 1))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e20b45db-f108-4570-8ba8-db081a78a03d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>     name (age + 1.0)\n1   Eddie          60\n2 Michael          NA\n3    Andy          31\n4  Justin          20\n5     Tom           9\n6     Ann          11\n\n</pre>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>     name (age + 1.0)\n1   Eddie          60\n2 Michael          NA\n3    Andy          31\n4  Justin          20\n5     Tom           9\n6     Ann          11\n\n</pre>"]}}],"execution_count":0},{"cell_type":"code","source":["%r\n\n# Select people older than 21\nhead(where(df, df$age > 21))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"85a02314-cecb-48fc-827f-d62adc82d655"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>  Height age gender    name\n1     NA  59   &lt;NA&gt;   Eddie\n2     NA  30   &lt;NA&gt;    Andy\n3    175  44 Female Hillary\n4     NA  41   male    Mike\n\n</pre>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>  Height age gender    name\n1     NA  59   &lt;NA&gt;   Eddie\n2     NA  30   &lt;NA&gt;    Andy\n3    175  44 Female Hillary\n4     NA  41   male    Mike\n\n</pre>"]}}],"execution_count":0},{"cell_type":"code","source":["%r\n\n# Row filtering: Select people between 7 and 31\nhead(where(df, df$age > 7 & df$age <=31))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ff7f4776-e308-4ced-8177-b2e0eb4e394e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>  Height age gender   name\n1     NA  30   &lt;NA&gt;   Andy\n2     NA  19   male Justin\n3     NA   8   male    Tom\n4     NA  10 Female    Ann\n\n</pre>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>  Height age gender   name\n1     NA  30   &lt;NA&gt;   Andy\n2     NA  19   male Justin\n3     NA   8   male    Tom\n4     NA  10 Female    Ann\n\n</pre>"]}}],"execution_count":0},{"cell_type":"code","source":["%r\n\n# Count people by age\nhead(count(groupBy(df, \"age\")))\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"beb12bce-40a4-4331-a8bf-0fcae829dfa1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>  age count\n1  19     1\n2  NA     1\n3  41     1\n4  10     1\n5  44     1\n6   8     1\n\n</pre>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>  age count\n1  19     1\n2  NA     1\n3  41     1\n4  10     1\n5  44     1\n6   8     1\n\n</pre>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Some DataFrame operations using **Scala**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6d6795cc-5a70-4927-a467-88b7f2d1d027"}}},{"cell_type":"code","source":["%scala\n\nimport org.apache.spark.sql.SparkSession\n\nval spark = SparkSession\n  .builder()\n  .appName(\"Module 2 with Scala\")\n  .getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cdd3b01b-a11a-4731-895f-67a6a7b8d225"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">import org.apache.spark.sql.SparkSession\nspark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@5f7ee532\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">import org.apache.spark.sql.SparkSession\nspark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@5f7ee532\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%scala\n\nval df = spark.read.json(\"dbfs:/FileStore/module2/json2_1.json\")\n\n// Displays the content of the DataFrame to stdout\ndf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b86845ce-2bc6-468a-9e33-a682bffacad9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"df","typeStr":"org.apache.spark.sql.DataFrame","schema":{"type":"struct","fields":[{"name":"Height","type":"long","nullable":true,"metadata":{}},{"name":"age","type":"long","nullable":true,"metadata":{}},{"name":"gender","type":"string","nullable":true,"metadata":{}},{"name":"name","type":"string","nullable":true,"metadata":{}}]},"tableIdentifier":null}],"data":"<div class=\"ansiout\">+------+----+------+-------+\n|Height| age|gender|   name|\n+------+----+------+-------+\n|  null|  59|  null|  Eddie|\n|   195|null|  null|Michael|\n|  null|  30|  null|   Andy|\n|  null|  19|  male| Justin|\n|  null|   8|  male|    Tom|\n|  null|  10|Female|    Ann|\n|   175|  44|Female|Hillary|\n|  null|  41|  male|   Mike|\n+------+----+------+-------+\n\ndf: org.apache.spark.sql.DataFrame = [Height: bigint, age: bigint ... 2 more fields]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+----+------+-------+\nHeight| age|gender|   name|\n+------+----+------+-------+\n  null|  59|  null|  Eddie|\n   195|null|  null|Michael|\n  null|  30|  null|   Andy|\n  null|  19|  male| Justin|\n  null|   8|  male|    Tom|\n  null|  10|Female|    Ann|\n   175|  44|Female|Hillary|\n  null|  41|  male|   Mike|\n+------+----+------+-------+\n\ndf: org.apache.spark.sql.DataFrame = [Height: bigint, age: bigint ... 2 more fields]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%scala\n\n// This import is needed to use the $-notation\nimport spark.implicits._\ndf.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1b39c7f2-b0af-453d-81f3-3c413d611a64"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- Height: long (nullable = true)\n |-- age: long (nullable = true)\n |-- gender: string (nullable = true)\n |-- name: string (nullable = true)\n\nimport spark.implicits._\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- Height: long (nullable = true)\n-- age: long (nullable = true)\n-- gender: string (nullable = true)\n-- name: string (nullable = true)\n\nimport spark.implicits._\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%scala\n\n// Select only the \"name\" column\ndf.select(\"name\").show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a13e4b85-cad4-4e62-8637-2c1dd349076c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-------+\n|   name|\n+-------+\n|  Eddie|\n|Michael|\n|   Andy|\n| Justin|\n|    Tom|\n|    Ann|\n|Hillary|\n|   Mike|\n+-------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+\n   name|\n+-------+\n  Eddie|\nMichael|\n   Andy|\n Justin|\n    Tom|\n    Ann|\nHillary|\n   Mike|\n+-------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%scala\n\n// Select everybody, but increment the age by 1\ndf.select($\"name\", $\"age\" + 1).show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4540bfa8-6603-4dc7-b385-4a2e77a0b52f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-------+---------+\n|   name|(age + 1)|\n+-------+---------+\n|  Eddie|       60|\n|Michael|     null|\n|   Andy|       31|\n| Justin|       20|\n|    Tom|        9|\n|    Ann|       11|\n|Hillary|       45|\n|   Mike|       42|\n+-------+---------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+---------+\n   name|(age + 1)|\n+-------+---------+\n  Eddie|       60|\nMichael|     null|\n   Andy|       31|\n Justin|       20|\n    Tom|        9|\n    Ann|       11|\nHillary|       45|\n   Mike|       42|\n+-------+---------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%scala\n\n// Select people older than 21\ndf.filter($\"age\" > 21).show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f2b92644-4a59-48a3-a854-a90af40f956b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+------+---+------+-------+\n|Height|age|gender|   name|\n+------+---+------+-------+\n|  null| 59|  null|  Eddie|\n|  null| 30|  null|   Andy|\n|   175| 44|Female|Hillary|\n|  null| 41|  male|   Mike|\n+------+---+------+-------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+---+------+-------+\nHeight|age|gender|   name|\n+------+---+------+-------+\n  null| 59|  null|  Eddie|\n  null| 30|  null|   Andy|\n   175| 44|Female|Hillary|\n  null| 41|  male|   Mike|\n+------+---+------+-------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%scala\n\n//  Row filtering: Select people between 7 and 31\ndf.filter($\"age\" > 7 && $\"age\"<= 31).show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1f831849-b838-4854-a401-44aaa02a7d26"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+------+---+------+------+\n|Height|age|gender|  name|\n+------+---+------+------+\n|  null| 30|  null|  Andy|\n|  null| 19|  male|Justin|\n|  null|  8|  male|   Tom|\n|  null| 10|Female|   Ann|\n+------+---+------+------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+---+------+------+\nHeight|age|gender|  name|\n+------+---+------+------+\n  null| 30|  null|  Andy|\n  null| 19|  male|Justin|\n  null|  8|  male|   Tom|\n  null| 10|Female|   Ann|\n+------+---+------+------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%scala\n\n// Count people by age\ndf.groupBy(\"age\").count().show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ffc68d21-1385-4a86-a4d0-28954ef1f4c7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----+-----+\n| age|count|\n+----+-----+\n|  19|    1|\n|null|    1|\n|  41|    1|\n|  10|    1|\n|  44|    1|\n|   8|    1|\n|  59|    1|\n|  30|    1|\n+----+-----+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+-----+\n age|count|\n+----+-----+\n  19|    1|\nnull|    1|\n  41|    1|\n  10|    1|\n  44|    1|\n   8|    1|\n  59|    1|\n  30|    1|\n+----+-----+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Running SQL"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2adaf7c2-9fe1-4c74-8abf-6cbb6f2adf42"}}},{"cell_type":"markdown","source":["### SQL with PySpark"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"559b576d-a6c4-45e4-a6a8-ff700502f84d"}}},{"cell_type":"code","source":["# Register the DataFrame as a global temporary view\ndf.createGlobalTempView(\"people\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4d6d358d-66d1-4e15-90a2-1f10af236ffb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3486262008950783&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\"># Register the DataFrame as a global temporary view</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>df<span class=\"ansi-blue-fg\">.</span>createGlobalTempView<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;people&#34;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;df&#39; is not defined</div>","errorSummary":"<span class=\"ansi-red-fg\">NameError</span>: name &#39;df&#39; is not defined","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3486262008950783&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\"># Register the DataFrame as a global temporary view</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>df<span class=\"ansi-blue-fg\">.</span>createGlobalTempView<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;people&#34;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;df&#39; is not defined</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Global temporary view is tied to a system preserved database `global_temp`\nspark.sql(\"SELECT * FROM global_temp.people\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2e1025e3-93b7-4f5f-bc4f-8b225b91b729"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Global temporary view is cross-session\nspark.newSession().sql(\"SELECT * FROM global_temp.people\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"af34cb7c-3022-45b5-8dfc-955045f27c95"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### SQL With Scala"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"858c1a4b-d54d-4455-8bd9-0f6c9fccccf3"}}},{"cell_type":"code","source":["%scala\n// Register the DataFrame as a SQL temporary view\ndf.createOrReplaceTempView(\"people\")\n\nval sqlDF = spark.sql(\"SELECT * FROM people\")\nsqlDF.show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a254f343-ae6f-4e62-94c6-cc19dede6a97"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### SQL With R"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0b01f0b8-5551-40c8-9179-0159abd9c7e0"}}},{"cell_type":"code","source":["%r\ndf <- sql(\"SELECT * FROM table\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ae9b7ac4-97b4-4b3b-b032-a828c6ab08d9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Creating and organising Data sources and DataSets"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5fcb5a91-2353-4865-be2b-698cf1029915"}}},{"cell_type":"markdown","source":["### Loading data, bucketing data with PySpark"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e1a1d1f5-4484-4b76-9532-520172f0631a"}}},{"cell_type":"markdown","source":["If you are running this out of Databricks environment, run submit command:\n```\n  ./bin/spark-submit your/path/to/python.py\n```"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"68388b5f-9067-4027-b96d-706752504c6a"}}},{"cell_type":"code","source":["# $example on:init_session$\nfrom pyspark.sql import SparkSession\n\n# $example on:schema_inferring$\nfrom pyspark.sql import Row\n\n# Import data types\nfrom pyspark.sql.types import StringType, StructType, StructField"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fa5480df-6571-4b39-b927-5055a85acec7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# parquet\n\ndf = spark.read.parquet(\"dbfs:/FileStore/module2/users.parquet\")\ndf.select(\"name\", \"favorite_color\").write.save(\"dbfs:/FileStore/module2/namesAndFavColors.parquet\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"42592449-146c-4678-838d-84befa4ec634"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#json\n\ndf = spark.read.load(\"dbfs:/FileStore/module2/people.json\", format=\"json\")\ndf.select(\"name\", \"age\").write.save(\"dbfs:/FileStore/module2/namesAndAges.parquet\", format=\"parquet\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c1bfdba2-674a-4dec-8711-205ac072212c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#csv\ndf = spark.read.load(\"dbfs:/FileStore/module2/people.csv\",\n                     format=\"csv\", sep=\";\", inferSchema=\"true\", header=\"true\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9041f4fd-b0c6-4084-9ff1-b9ef82710a54"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#ORC \ndf = spark.read.orc(\"dbfs:/FileStore/module2/users.orc\")\n(df.write.format(\"orc\")\n    .option(\"orc.bloom.filter.columns\", \"favorite_color\")\n    .option(\"orc.dictionary.key.threshold\", \"1.0\")\n    .option(\"orc.column.encoding.direct\", \"name\")\n    .save(\"users_with_options.orc\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"067c12b7-b4fe-4394-974b-acc9c8ae20df"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Parquet\n\ndf = spark.read.parquet(\"dbfs:/FileStore/module2/users.parquet\")\n(df.write.format(\"parquet\")\n    .option(\"parquet.bloom.filter.enabled#favorite_color\", \"true\")\n    .option(\"parquet.bloom.filter.expected.ndv#favorite_color\", \"1000000\")\n    .option(\"parquet.enable.dictionary\", \"true\")\n    .option(\"parquet.page.write-checksum.enabled\", \"false\")\n    .save(\"users_with_options.parquet\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eb57ff43-e873-42b3-82ba-4266694d1f3b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Reading Parquet file directly with SQL\ndf = spark.sql(\"SELECT * FROM parquet.`dbfs:/FileStore/module2/users.parquet`\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3f7bce0f-2288-43c2-b0b8-eb6d555e9238"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Saving and bucketing with PySpark"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d574f281-5593-4cc2-9536-b038550f6a20"}}},{"cell_type":"code","source":["# Bucketing and sorting are applicable only to persistent tables (!!!) Delta tables do not support bucketing and sorting!\ndf.write.bucketBy(42, \"name\").sortBy(\"age\").saveAsTable(\"people_bucketed\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0d52aade-890c-4116-a732-cc84ea6a792a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3486262008950802&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\"># Bucketing and sorting are applicable only to persistent tables</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>df<span class=\"ansi-blue-fg\">.</span>write<span class=\"ansi-blue-fg\">.</span>bucketBy<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">42</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;name&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>sortBy<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;age&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>saveAsTable<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;people_bucketed&#34;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/readwriter.py</span> in <span class=\"ansi-cyan-fg\">saveAsTable</span><span class=\"ansi-blue-fg\">(self, name, format, mode, partitionBy, **options)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1183</span>         <span class=\"ansi-green-fg\">if</span> format <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1184</span>             self<span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>format<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1185</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>_jwrite<span class=\"ansi-blue-fg\">.</span>saveAsTable<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1186</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1187</span>     def json(self, path, mode=None, compression=None, dateFormat=None, timestampFormat=None,\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    121</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    122</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 123</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    124</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: Cannot convert bucketing with sort columns to a transform: 42 buckets, bucket columns: [name], sort columns: [age]</div>","errorSummary":"<span class=\"ansi-red-fg\">AnalysisException</span>: Cannot convert bucketing with sort columns to a transform: 42 buckets, bucket columns: [name], sort columns: [age]","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3486262008950802&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\"># Bucketing and sorting are applicable only to persistent tables</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>df<span class=\"ansi-blue-fg\">.</span>write<span class=\"ansi-blue-fg\">.</span>bucketBy<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">42</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;name&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>sortBy<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;age&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>saveAsTable<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;people_bucketed&#34;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/readwriter.py</span> in <span class=\"ansi-cyan-fg\">saveAsTable</span><span class=\"ansi-blue-fg\">(self, name, format, mode, partitionBy, **options)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1183</span>         <span class=\"ansi-green-fg\">if</span> format <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1184</span>             self<span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>format<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1185</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>_jwrite<span class=\"ansi-blue-fg\">.</span>saveAsTable<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1186</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1187</span>     def json(self, path, mode=None, compression=None, dateFormat=None, timestampFormat=None,\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    121</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    122</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 123</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    124</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: Cannot convert bucketing with sort columns to a transform: 42 buckets, bucket columns: [name], sort columns: [age]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#create and save to Hive table\ndf.write.saveAsTable(\"people_bucketed\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1df7f5aa-f9d0-42db-9b57-cdf406de8a3b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\nSELECT * FROM people_bucketed"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d82e7837-844c-4f6a-9882-6f8f849ee1e6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Alyssa",null,[3,9,15,20]],["Ben","red",[]]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"favorite_color","type":"\"string\"","metadata":"{}"},{"name":"favorite_numbers","type":"{\"type\":\"array\",\"elementType\":\"integer\",\"containsNull\":true}","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>favorite_color</th><th>favorite_numbers</th></tr></thead><tbody><tr><td>Alyssa</td><td>null</td><td>List(3, 9, 15, 20)</td></tr><tr><td>Ben</td><td>red</td><td>List()</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# partitioning can be used with both save and saveAsTable when using the Dataset APIs\ndf.write.partitionBy(\"favorite_color\").format(\"parquet\").save(\"namesPartByColor.parquet\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b0a2f626-facf-4a37-abb5-93fd9638f01b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# but it is possible to use both partitioning and bucketing in Delta tables; but pySpark is esentially capable of this\ndf = spark.read.parquet(\"dbfs:/FileStore/module2/users.parquet\")\n(df\n    .write\n    .partitionBy(\"favorite_color\")\n    .bucketBy(42, \"name\")\n    .saveAsTable(\"users_partitioned_bucketed\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"13b5db98-8d41-4508-bf24-ade4d38ac0ac"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3486262008950804&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\"># but it is possible to use both partitioning and bucketing</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> df <span class=\"ansi-blue-fg\">=</span> spark<span class=\"ansi-blue-fg\">.</span>read<span class=\"ansi-blue-fg\">.</span>parquet<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;dbfs:/FileStore/module2/users.parquet&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\"> (df\n</span><span class=\"ansi-green-intense-fg ansi-bold\">      4</span>     <span class=\"ansi-blue-fg\">.</span>write\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>     <span class=\"ansi-blue-fg\">.</span>partitionBy<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;favorite_color&#34;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/readwriter.py</span> in <span class=\"ansi-cyan-fg\">saveAsTable</span><span class=\"ansi-blue-fg\">(self, name, format, mode, partitionBy, **options)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1183</span>         <span class=\"ansi-green-fg\">if</span> format <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1184</span>             self<span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>format<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1185</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>_jwrite<span class=\"ansi-blue-fg\">.</span>saveAsTable<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1186</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1187</span>     def json(self, path, mode=None, compression=None, dateFormat=None, timestampFormat=None,\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    121</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    122</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 123</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    124</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: Partition transform expression `bucket` is not supported for Delta tables. You can use the CLUSTERED BY clause in a SQL CREATE TABLE statement to create a bucketed table.</div>","errorSummary":"<span class=\"ansi-red-fg\">AnalysisException</span>: Partition transform expression `bucket` is not supported for Delta tables. You can use the CLUSTERED BY clause in a SQL CREATE TABLE statement to create a bucketed table.","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3486262008950804&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\"># but it is possible to use both partitioning and bucketing</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> df <span class=\"ansi-blue-fg\">=</span> spark<span class=\"ansi-blue-fg\">.</span>read<span class=\"ansi-blue-fg\">.</span>parquet<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;dbfs:/FileStore/module2/users.parquet&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\"> (df\n</span><span class=\"ansi-green-intense-fg ansi-bold\">      4</span>     <span class=\"ansi-blue-fg\">.</span>write\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>     <span class=\"ansi-blue-fg\">.</span>partitionBy<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;favorite_color&#34;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/readwriter.py</span> in <span class=\"ansi-cyan-fg\">saveAsTable</span><span class=\"ansi-blue-fg\">(self, name, format, mode, partitionBy, **options)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1183</span>         <span class=\"ansi-green-fg\">if</span> format <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1184</span>             self<span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>format<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1185</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>_jwrite<span class=\"ansi-blue-fg\">.</span>saveAsTable<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1186</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1187</span>     def json(self, path, mode=None, compression=None, dateFormat=None, timestampFormat=None,\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    121</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    122</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 123</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    124</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: Partition transform expression `bucket` is not supported for Delta tables. You can use the CLUSTERED BY clause in a SQL CREATE TABLE statement to create a bucketed table.</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Loading data, bucketing data with SparkR"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"df433bc7-aaa5-4151-8da8-89d9b9206fb3"}}},{"cell_type":"code","source":["%r\n\nlibrary(SparkR)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5b5ec6e1-da2c-4428-822d-4e3d58756033"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>\nAttaching package: ‘SparkR’\n\nThe following object is masked _by_ ‘.GlobalEnv’:\n\n    setLocalProperty\n\nThe following objects are masked from ‘package:stats’:\n\n    cov, filter, lag, na.omit, predict, sd, var, window\n\nThe following objects are masked from ‘package:base’:\n\n    as.data.frame, colnames, colnames&lt;-, drop, endsWith, intersect,\n    rank, rbind, sample, startsWith, subset, summary, transform, union\n\n\n</pre>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>\nAttaching package: ‘SparkR’\n\nThe following object is masked _by_ ‘.GlobalEnv’:\n\n    setLocalProperty\n\nThe following objects are masked from ‘package:stats’:\n\n    cov, filter, lag, na.omit, predict, sd, var, window\n\nThe following objects are masked from ‘package:base’:\n\n    as.data.frame, colnames, colnames&lt;-, drop, endsWith, intersect,\n    rank, rbind, sample, startsWith, subset, summary, transform, union\n\n\n</pre>"]}}],"execution_count":0},{"cell_type":"code","source":["%r\n\n# reading from Parquet\ndf <- read.df(\"dbfs:/FileStore/module2/users.parquet\")\nwrite.df(select(df, \"name\", \"favorite_color\"), \"dbfs:/FileStore/module2/namesAndFavColors.parquet\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1dbb1eca-626b-4d02-89cf-b8d45bf44b6a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<pre style = 'font-size:10p'>\n</pre>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style = 'font-size:10p'>\n</pre>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<pre style = 'font-size:10p'>Error: Error in load : analysis error - Incompatible format detected.\n\nYou are trying to read from `dbfs:/FileStore/module2/users.parquet` using Databricks Delta, but there is no\ntransaction log present. Check the upstream job to make sure that it is writing\nusing format(&quot;delta&quot;) and that you are trying to read from the table base path.\n\nTo disable this check, SET spark.databricks.delta.formatCheck.enabled=false\nTo learn more about Delta, see https://docs.microsoft.com/azure/databricks/delta/index\n\n\n\n</pre>","errorSummary":"Error : Error in load : analysis error - Incompatible format detected.\n\nYou are trying to read from `dbfs:/FileStore/module2/users.parquet` using Databricks Delta, but there is no\ntransaction log present. Check the upstream job to make sure that it is writing\nusing format(\"delta\") and that you are trying to read from the table base path.\n\nTo disable this check, SET spark.databricks.delta.formatCheck.enabled=false\nTo learn more about Delta, see https://docs.microsoft.com/azure/databricks/delta/index\n\nSome(<code style = 'font-size:10p'> Error: Error in load : analysis error - Incompatible format detected. </code>)","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style = 'font-size:10p'>Error: Error in load : analysis error - Incompatible format detected.\n\nYou are trying to read from `dbfs:/FileStore/module2/users.parquet` using Databricks Delta, but there is no\ntransaction log present. Check the upstream job to make sure that it is writing\nusing format(&quot;delta&quot;) and that you are trying to read from the table base path.\n\nTo disable this check, SET spark.databricks.delta.formatCheck.enabled=false\nTo learn more about Delta, see https://docs.microsoft.com/azure/databricks/delta/index\n\n\n\n</pre>"]}}],"execution_count":0},{"cell_type":"code","source":["%r\n# Reading JSON\ndf <- read.df(\"dbfs:/FileStore/module2/people.json\", \"json\")\nnamesAndAges <- select(df, \"name\", \"age\")\n#write.df(namesAndAges, \"dbfs:/FileStore/module2/namesAndAges.parquet\", \"parquet\")  Will create error, turn overwrite ON\nwrite.df(namesAndAges, \"dbfs:/FileStore/module2/namesAndAges.parquet\", \"parquet\", \"overwrite\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b02418d5-5ec1-453a-851b-4a68a2114b91"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>\n</pre>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>\n</pre>"]}}],"execution_count":0},{"cell_type":"code","source":["%r\n# Reading CSV\ndf <- read.df(\"dbfs:/FileStore/module2/people.csv\", \"csv\", sep = \";\", inferSchema = TRUE, header = TRUE)\nnamesAndAges <- select(df, \"name\", \"age\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"05990037-fa85-474a-b545-fa8f6751746a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>\n</pre>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>\n</pre>"]}}],"execution_count":0},{"cell_type":"code","source":["%r\n# Write to ORC\ndf <- read.df(\"dbfs:/FileStore/module2/users.orc\", \"orc\")\nwrite.orc(df, \"users_with_options.orc\", orc.bloom.filter.columns = \"favorite_color\", orc.dictionary.key.threshold = 1.0, orc.column.encoding.direct = \"name\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"efeefd11-ee46-4ed9-83bb-9a5fed3e4620"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<pre style = 'font-size:10p'>\n</pre>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style = 'font-size:10p'>\n</pre>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<pre style = 'font-size:10p'>Error: Error in orc : analysis error - path dbfs:/users_with_options.orc already exists.\n\n\n</pre>","errorSummary":"Error : Error in orc : analysis error - path dbfs:/users_with_options.orc already exists.\nSome(<code style = 'font-size:10p'> Error: Error in orc : analysis error - path dbfs:/users_with_options.orc already exists. </code>)","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style = 'font-size:10p'>Error: Error in orc : analysis error - path dbfs:/users_with_options.orc already exists.\n\n\n</pre>"]}}],"execution_count":0},{"cell_type":"code","source":["%r\n# Save to Parquet file\nf <- read.df(\"dbfs:/FileStore/module2/users.parquet\", \"parquet\")\nwrite.parquet(df, \"users_with_options.parquet\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ab123a97-7745-460b-a2c3-18e2ac0cf589"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<pre style = 'font-size:10p'>\n</pre>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style = 'font-size:10p'>\n</pre>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<pre style = 'font-size:10p'>Error: Error in parquet : analysis error - path dbfs:/users_with_options.parquet already exists.\n\n\n</pre>","errorSummary":"Error : Error in parquet : analysis error - path dbfs:/users_with_options.parquet already exists.\nSome(<code style = 'font-size:10p'> Error: Error in parquet : analysis error - path dbfs:/users_with_options.parquet already exists. </code>)","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style = 'font-size:10p'>Error: Error in parquet : analysis error - path dbfs:/users_with_options.parquet already exists.\n\n\n</pre>"]}}],"execution_count":0},{"cell_type":"code","source":["%r\ndf <- sql(\"SELECT * FROM parquet.`dbfs:/FileStore/module2/users.parquet`\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a3f8ef2f-944b-43d8-8b08-770c5f7fe3d7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>\n</pre>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>\n</pre>"]}}],"execution_count":0},{"cell_type":"code","source":["%r\nhead(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c9b3364f-2e4e-42ac-92c6-a9bf3a1542de"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>    name favorite_color favorite_numbers\n1 Alyssa           &lt;NA&gt;     3, 9, 15, 20\n2    Ben            red             NULL\n\n</pre>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style = 'font-size:10p'></pre><pre style = 'font-size:10p'>    name favorite_color favorite_numbers\n1 Alyssa           &lt;NA&gt;     3, 9, 15, 20\n2    Ben            red             NULL\n\n</pre>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Saving and bucketing"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7b798605-4a64-461f-b2cb-6b2ea75dd5d1"}}},{"cell_type":"markdown","source":["No support for R"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ca6d215b-be99-41a2-84bc-ffa8200dfdc9"}}},{"cell_type":"markdown","source":["### Loading data, bucketing data with Scala"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7233c4d9-a24f-4b7e-ad13-be656d6b0f5a"}}},{"cell_type":"markdown","source":["we will disable formatCheck on Databrick SET spark.databricks.delta.formatCheck.enabled=false"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f773e3d3-661e-4416-8a5e-99a7a17c18c3"}}},{"cell_type":"code","source":["%scala\n\nval usersDF = spark.read.load(\"dbfs:/FileStore/module2/users.parquet\")\nusersDF.select(\"name\", \"favorite_color\").write.save(\"namesAndFavColors.parquet\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"78e904c9-7540-4103-b4e8-fd6dbc81295a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"<div class=\"ansiout\">command-3486262008950811:3: error: value write is not a member of Unit\nusersDF.select(&quot;name&quot;, &quot;favorite_color&quot;).write.save(&quot;namesAndFavColors.parquet&quot;).write.mode(&quot;overwrite&quot;)\n                                                                                 ^\n</div>","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["%scala\n\n// Reading JSON\nval peopleDF = spark.read.format(\"json\").load(\"dbfs:/FileStore/module2/people.json\")\npeopleDF.select(\"name\", \"age\").write.format(\"parquet\").save(\"namesAndAges.parquet\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a4d6c8d5-8587-4560-82ae-0dd67d9659f3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"peopleDF","typeStr":"org.apache.spark.sql.DataFrame","schema":{"type":"struct","fields":[{"name":"age","type":"long","nullable":true,"metadata":{}},{"name":"name","type":"string","nullable":true,"metadata":{}}]},"tableIdentifier":null}],"data":"<div class=\"ansiout\">peopleDF: org.apache.spark.sql.DataFrame = [age: bigint, name: string]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">peopleDF: org.apache.spark.sql.DataFrame = [age: bigint, name: string]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%scala\n\n// reading CSV\n\nval peopleDFCsv = spark.read.format(\"csv\")\n  .option(\"sep\", \";\")\n  .option(\"inferSchema\", \"true\")\n  .option(\"header\", \"true\")\n  .load(\"dbfs:/FileStore/module2/people.csv\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d30381dc-a62f-44da-832c-70f2471b323b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"peopleDFCsv","typeStr":"org.apache.spark.sql.DataFrame","schema":{"type":"struct","fields":[{"name":"name","type":"string","nullable":true,"metadata":{}},{"name":"age","type":"integer","nullable":true,"metadata":{}},{"name":"job","type":"string","nullable":true,"metadata":{}}]},"tableIdentifier":null}],"data":"<div class=\"ansiout\">peopleDFCsv: org.apache.spark.sql.DataFrame = [name: string, age: int ... 1 more field]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">peopleDFCsv: org.apache.spark.sql.DataFrame = [name: string, age: int ... 1 more field]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%scala\n\n//Writing to ORC data\nusersDF.write.format(\"orc\")\n  .option(\"orc.bloom.filter.columns\", \"favorite_color\")\n  .option(\"orc.dictionary.key.threshold\", \"1.0\")\n  .option(\"orc.column.encoding.direct\", \"name\")\n  .save(\"users_with_options.orc\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fe28c1be-6c63-4fab-86ac-72447418d8b8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"<div class=\"ansiout\">command-3486262008950816:3: error: not found: value usersDF\nusersDF.write.format(&quot;orc&quot;)\n^\n</div>","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["%scala\n\n// writing to Parquet file\n\nusersDF.write.format(\"parquet\")\n  .option(\"parquet.bloom.filter.enabled#favorite_color\", \"true\")\n  .option(\"parquet.bloom.filter.expected.ndv#favorite_color\", \"1000000\")\n  .option(\"parquet.enable.dictionary\", \"true\")\n  .option(\"parquet.page.write-checksum.enabled\", \"false\")\n  .save(\"users_with_options.parquet\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8fa8caf4-047c-4a46-b340-563355e50103"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["%scala\n// reading directly using SQL\nval sqlDF = spark.sql(\"SELECT * FROM parquet.`dbfs:/FileStore/module2/users.parquet`\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"51a16b34-b8e3-4c2f-b0ec-e0c634d8d6ac"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"sqlDF","typeStr":"org.apache.spark.sql.DataFrame","schema":{"type":"struct","fields":[{"name":"name","type":"string","nullable":true,"metadata":{}},{"name":"favorite_color","type":"string","nullable":true,"metadata":{}},{"name":"favorite_numbers","type":{"type":"array","elementType":"integer","containsNull":true},"nullable":true,"metadata":{}}]},"tableIdentifier":null}],"data":"<div class=\"ansiout\">sqlDF: org.apache.spark.sql.DataFrame = [name: string, favorite_color: string ... 1 more field]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">sqlDF: org.apache.spark.sql.DataFrame = [name: string, favorite_color: string ... 1 more field]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Saving and bucketing"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"53c28485-f465-4f0e-be7d-45fed8bb647f"}}},{"cell_type":"code","source":["%scala\n// bucketing and sorting\npeopleDF.write.bucketBy(42, \"name\").sortBy(\"age\").saveAsTable(\"people_bucketed\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"93c38fcd-a7d4-4fbc-94a1-143b4e37eae1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\">\tat org.apache.spark.sql.connector.catalog.CatalogV2Implicits$BucketSpecHelper.asTransform(CatalogV2Implicits.scala:43)\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$partitioningAsV2$4(DataFrameWriter.scala:853)\n\tat scala.Option.map(Option.scala:230)\n\tat org.apache.spark.sql.DataFrameWriter.partitioningAsV2(DataFrameWriter.scala:853)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:749)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:699)\n\tat $line6dda9b53306348dd983bfe6456bcd63f43.$read$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-3486262008950821:2)\n\tat $line6dda9b53306348dd983bfe6456bcd63f43.$read$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-3486262008950821:46)\n\tat $line6dda9b53306348dd983bfe6456bcd63f43.$read$$iw$$iw$$iw$$iw.&lt;init&gt;(command-3486262008950821:48)\n\tat $line6dda9b53306348dd983bfe6456bcd63f43.$read$$iw$$iw$$iw.&lt;init&gt;(command-3486262008950821:50)\n\tat $line6dda9b53306348dd983bfe6456bcd63f43.$read$$iw$$iw.&lt;init&gt;(command-3486262008950821:52)\n\tat $line6dda9b53306348dd983bfe6456bcd63f43.$read$$iw.&lt;init&gt;(command-3486262008950821:54)\n\tat $line6dda9b53306348dd983bfe6456bcd63f43.$read.&lt;init&gt;(command-3486262008950821:56)\n\tat $line6dda9b53306348dd983bfe6456bcd63f43.$read$.&lt;init&gt;(command-3486262008950821:60)\n\tat $line6dda9b53306348dd983bfe6456bcd63f43.$read$.&lt;clinit&gt;(command-3486262008950821)\n\tat $line6dda9b53306348dd983bfe6456bcd63f43.$eval$.$print$lzycompute(&lt;notebook&gt;:7)\n\tat $line6dda9b53306348dd983bfe6456bcd63f43.$eval$.$print(&lt;notebook&gt;:6)\n\tat $line6dda9b53306348dd983bfe6456bcd63f43.$eval.$print(&lt;notebook&gt;)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:745)\n\tat scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1021)\n\tat scala.tools.nsc.interpreter.IMain.$anonfun$interpret$1(IMain.scala:574)\n\tat scala.reflect.internal.util.ScalaClassLoader.asContext(ScalaClassLoader.scala:41)\n\tat scala.reflect.internal.util.ScalaClassLoader.asContext$(ScalaClassLoader.scala:37)\n\tat scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:41)\n\tat scala.tools.nsc.interpreter.IMain.loadAndRunReq$1(IMain.scala:573)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:600)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:570)\n\tat com.databricks.backend.daemon.driver.DriverILoop.execute(DriverILoop.scala:219)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal.$anonfun$repl$1(ScalaDriverLocal.scala:235)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.backend.daemon.driver.DriverLocal$TrapExitInternal$.trapExit(DriverLocal.scala:887)\n\tat com.databricks.backend.daemon.driver.DriverLocal$TrapExit$.apply(DriverLocal.scala:840)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal.repl(ScalaDriverLocal.scala:235)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$11(DriverLocal.scala:526)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:266)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:261)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:258)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:50)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:305)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:297)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:50)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:503)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:689)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:681)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:522)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:634)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:427)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:370)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:221)\n\tat java.lang.Thread.run(Thread.java:748)</div>","errorSummary":"AnalysisException: Cannot convert bucketing with sort columns to a transform: 42 buckets, bucket columns: [name], sort columns: [age]","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\tat org.apache.spark.sql.connector.catalog.CatalogV2Implicits$BucketSpecHelper.asTransform(CatalogV2Implicits.scala:43)\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$partitioningAsV2$4(DataFrameWriter.scala:853)\n\tat scala.Option.map(Option.scala:230)\n\tat org.apache.spark.sql.DataFrameWriter.partitioningAsV2(DataFrameWriter.scala:853)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:749)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:699)\n\tat $line6dda9b53306348dd983bfe6456bcd63f43.$read$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-3486262008950821:2)\n\tat $line6dda9b53306348dd983bfe6456bcd63f43.$read$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-3486262008950821:46)\n\tat $line6dda9b53306348dd983bfe6456bcd63f43.$read$$iw$$iw$$iw$$iw.&lt;init&gt;(command-3486262008950821:48)\n\tat $line6dda9b53306348dd983bfe6456bcd63f43.$read$$iw$$iw$$iw.&lt;init&gt;(command-3486262008950821:50)\n\tat $line6dda9b53306348dd983bfe6456bcd63f43.$read$$iw$$iw.&lt;init&gt;(command-3486262008950821:52)\n\tat $line6dda9b53306348dd983bfe6456bcd63f43.$read$$iw.&lt;init&gt;(command-3486262008950821:54)\n\tat $line6dda9b53306348dd983bfe6456bcd63f43.$read.&lt;init&gt;(command-3486262008950821:56)\n\tat $line6dda9b53306348dd983bfe6456bcd63f43.$read$.&lt;init&gt;(command-3486262008950821:60)\n\tat $line6dda9b53306348dd983bfe6456bcd63f43.$read$.&lt;clinit&gt;(command-3486262008950821)\n\tat $line6dda9b53306348dd983bfe6456bcd63f43.$eval$.$print$lzycompute(&lt;notebook&gt;:7)\n\tat $line6dda9b53306348dd983bfe6456bcd63f43.$eval$.$print(&lt;notebook&gt;:6)\n\tat $line6dda9b53306348dd983bfe6456bcd63f43.$eval.$print(&lt;notebook&gt;)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:745)\n\tat scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1021)\n\tat scala.tools.nsc.interpreter.IMain.$anonfun$interpret$1(IMain.scala:574)\n\tat scala.reflect.internal.util.ScalaClassLoader.asContext(ScalaClassLoader.scala:41)\n\tat scala.reflect.internal.util.ScalaClassLoader.asContext$(ScalaClassLoader.scala:37)\n\tat scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:41)\n\tat scala.tools.nsc.interpreter.IMain.loadAndRunReq$1(IMain.scala:573)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:600)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:570)\n\tat com.databricks.backend.daemon.driver.DriverILoop.execute(DriverILoop.scala:219)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal.$anonfun$repl$1(ScalaDriverLocal.scala:235)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.backend.daemon.driver.DriverLocal$TrapExitInternal$.trapExit(DriverLocal.scala:887)\n\tat com.databricks.backend.daemon.driver.DriverLocal$TrapExit$.apply(DriverLocal.scala:840)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal.repl(ScalaDriverLocal.scala:235)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$11(DriverLocal.scala:526)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:266)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:261)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:258)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:50)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:305)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:297)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:50)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:503)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:689)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:681)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:522)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:634)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:427)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:370)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:221)\n\tat java.lang.Thread.run(Thread.java:748)</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%scala\n// partitiong\nusersDF.write.partitionBy(\"favorite_color\").format(\"parquet\").save(\"namesPartByColor.parquet\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ddee5d86-fd63-4f18-b6bb-536cdc2daac9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"<div class=\"ansiout\">command-3486262008950822:2: error: not found: value usersDF\nusersDF.write.partitionBy(&quot;favorite_color&quot;).format(&quot;parquet&quot;).save(&quot;namesPartByColor.parquet&quot;)\n^\n</div>","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["%scala\n// Partitionin and bucketing\n\nusersDF\n  .write\n  .partitionBy(\"favorite_color\")\n  .bucketBy(42, \"name\")\n  .saveAsTable(\"users_partitioned_bucketed\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"de8f8113-3f50-47ae-b31c-54f1aa81bae8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"<div class=\"ansiout\">command-3486262008950823:3: error: not found: value usersDF\nusersDF\n^\n</div>","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Organizing data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0b99dfd6-5e34-4173-bc9e-d90d60e8d84c"}}},{"cell_type":"markdown","source":["### Create Schemas and Assign DataTypes"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3539eb62-825c-4923-874c-7126c0c887e6"}}},{"cell_type":"markdown","source":["### Read and Write Data using the DataFrame Reader and Writer"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e619f175-9695-46d8-b050-593c968f8d3a"}}},{"cell_type":"markdown","source":["### Create and New Data Columns to the DataFrame using Expressions"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3d20af2a-d52c-43a8-b89b-703be41a64c4"}}},{"cell_type":"markdown","source":["### Filter the DataFrame using the \"Filter\" and \"Where\" Transformations"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f5216490-c28a-4d1f-8bf6-b954a4f481f1"}}},{"cell_type":"markdown","source":["### Ensure that the DataFrame has unique rows"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"39b14558-8f97-4f74-bf70-716c1f7239a5"}}},{"cell_type":"markdown","source":["### Detect and Drop Duplicates"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c5ca6b1f-99ac-4457-ad7b-3ad97fbb3820"}}},{"cell_type":"markdown","source":["### Augment the DataFrame by Adding New Rows"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fed12e22-7c8a-41a6-b00d-d69972ab1cf5"}}},{"cell_type":"markdown","source":["### Combine 2 or More DataFrames"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f883de98-a06b-422c-91c8-70790d972b60"}}},{"cell_type":"markdown","source":["### Order the DataFrame by Specific Columns"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"33015358-6474-4067-b85b-b821917ecbb5"}}},{"cell_type":"markdown","source":["### Renaming and Drop Columns from the DataFrame"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"55e16bdf-7ad4-46fc-bf5b-2a91299ade00"}}},{"cell_type":"markdown","source":["### Clean the DataFrame by detecting and Removing Missing or Bad Data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"90de1318-0408-4c9a-8dae-83267bc38455"}}},{"cell_type":"markdown","source":["### Create  User-Defined Spark Function"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3ee79510-baf8-411c-a1b4-34e930a863d4"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Py2-Module2","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2231556431298127}},"nbformat":4,"nbformat_minor":0}
