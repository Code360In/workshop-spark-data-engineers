{"cells":[{"cell_type":"markdown","source":["## Module 3"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8a01a7fe-d0ac-4659-b915-ab728b2b8b79"}}},{"cell_type":"markdown","source":["This file is running on Databricks cluster: **DBR 9.1 LTS | Spark 3.1.2 | Scala 2.12**\n\nNotebook has default language: **Python**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bf76331d-694b-4ee7-95da-c68fbf75fbcd"}}},{"cell_type":"markdown","source":["### Schema inference - semi-structured files"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fb75c29c-a24a-4ce6-86db-72402ebc9b56"}}},{"cell_type":"markdown","source":["Make sure that the files for module3 are loaded and use Spark API file connection"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6a65cb8a-061e-4e62-b042-94920a1a71cc"}}},{"cell_type":"code","source":["import pyspark"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ecdf3800-f566-4e5d-ba8a-5ba9e25d21df"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark.read.json(\"dbfs:/FileStore/module3/json1.json\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e443f07b-8fc1-47b1-a16b-21fa2b9396b6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[15]: DataFrame[a: bigint, b: bigint, c: bigint, d: bigint, e: bigint]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[15]: DataFrame[a: bigint, b: bigint, c: bigint, d: bigint, e: bigint]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark.read.json(\"dbfs:/FileStore/module3/json1.json\").printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c97b4f70-4618-424b-8353-4165bd4cc0d8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- a: long (nullable = true)\n |-- b: long (nullable = true)\n |-- c: long (nullable = true)\n |-- d: long (nullable = true)\n |-- e: long (nullable = true)\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- a: long (nullable = true)\n-- b: long (nullable = true)\n-- c: long (nullable = true)\n-- d: long (nullable = true)\n-- e: long (nullable = true)\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Actual file looks like and all types are long and nullable (!)\n```\n{\"a\":1, \"b\":2, \"c\":3}\n{\"e\":2, \"c\":3, \"b\":5}\n{\"a\":5, \"d\":7}\n```"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"91fdc172-ade3-4340-b4a8-878d83ce7b89"}}},{"cell_type":"code","source":["spark.read.json(\"dbfs:/FileStore/module3/json2.json\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"962fe1c0-64a8-4b10-a4ac-a7c10b13bb89"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[18]: DataFrame[a: string, b: bigint, c: double, d: bigint, e: bigint]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[18]: DataFrame[a: string, b: bigint, c: double, d: bigint, e: bigint]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark.read.json(\"dbfs:/FileStore/module3/json2.json\").printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"48a1e14d-dad3-4b9e-b105-75b7bd73d953"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- a: string (nullable = true)\n |-- b: long (nullable = true)\n |-- c: double (nullable = true)\n |-- d: long (nullable = true)\n |-- e: long (nullable = true)\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- a: string (nullable = true)\n-- b: long (nullable = true)\n-- c: double (nullable = true)\n-- d: long (nullable = true)\n-- e: long (nullable = true)\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Actual file looks like and all types are long and nullable (!)\n```\n{\"a\":1, \"b\":2, \"c\":3.1}\n{\"e\":2, \"c\":3, \"b\":5}\n{\"a\":\"5\", \"d\":7}\n```"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c568a705-4ce4-4f31-b349-039d79c54ab0"}}},{"cell_type":"markdown","source":["We can store results in dataFrame"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"19a0562c-35a6-435e-ad29-87e917df6611"}}},{"cell_type":"code","source":["df = spark.read.json(\"dbfs:/FileStore/module3/json2.json\")\ndf.printSchema()\ndf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"844611ec-39ac-4805-93ac-c3e9b216fa4b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- a: string (nullable = true)\n |-- b: long (nullable = true)\n |-- c: double (nullable = true)\n |-- d: long (nullable = true)\n |-- e: long (nullable = true)\n\n+----+----+----+----+----+\n|   a|   b|   c|   d|   e|\n+----+----+----+----+----+\n|   1|   2| 3.1|null|null|\n|null|   5| 3.0|null|   2|\n|   5|null|null|   7|null|\n+----+----+----+----+----+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- a: string (nullable = true)\n-- b: long (nullable = true)\n-- c: double (nullable = true)\n-- d: long (nullable = true)\n-- e: long (nullable = true)\n\n+----+----+----+----+----+\n   a|   b|   c|   d|   e|\n+----+----+----+----+----+\n   1|   2| 3.1|null|null|\nnull|   5| 3.0|null|   2|\n   5|null|null|   7|null|\n+----+----+----+----+----+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Read JSON file into dataframe\ndf = spark.read.format('org.apache.spark.sql.json') \\\n        .load(\"dbfs:/FileStore/module3/json2.json\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ba97d36d-3fe5-42a3-b715-903636addae0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["But we want to enforce schema to get correct import values; let's repeat for `json1.json` file"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8d4ffbcb-9bdd-4ed4-b54c-8871481700bd"}}},{"cell_type":"code","source":["from pyspark.sql.types import StructType,StructField,StringType,IntegerType,BooleanType,DoubleType"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8ac6ebd6-1db0-42c0-82ce-b6dd24ea4df3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["mojaShemica = StructType([\n  StructField(\"a\", IntegerType(), True),\n  StructField(\"b\", IntegerType(), True)])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5e56bf4e-a7bd-411f-895c-579a3d177179"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark.read.schema(mojaShemica).json(\"dbfs:/FileStore/module3/json1.json\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"086e402f-817f-4e00-b9e5-0fb166f16e3d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----+----+\n|   a|   b|\n+----+----+\n|   1|   2|\n|null|   5|\n|   5|null|\n+----+----+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+----+\n   a|   b|\n+----+----+\n   1|   2|\nnull|   5|\n   5|null|\n+----+----+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark.read.json(\"dbfs:/FileStore/module3/json1.json\").printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0a0ae7b6-dfa8-4ddb-95e2-0d3959d3a8e1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- a: long (nullable = true)\n |-- b: long (nullable = true)\n |-- c: long (nullable = true)\n |-- d: long (nullable = true)\n |-- e: long (nullable = true)\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- a: long (nullable = true)\n-- b: long (nullable = true)\n-- c: long (nullable = true)\n-- d: long (nullable = true)\n-- e: long (nullable = true)\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Playing with data\nNow let's create a more \"interesting\" JSON file"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"df623004-417e-4d36-8ac4-61d0fa67631b"}}},{"cell_type":"code","source":["[{\n  \"RecordNumber\": 2,\n  \"Zipcode\": 1000,\n  \"ZipCodeType\": \"STANDARD\",\n  \"City\": \"Ljubljana\",\n   \"State\":\"SI\"\n},\n{\n  \"RecordNumber\": 10,\n  \"Zipcode\": 3000,\n  \"ZipCodeType\": \"STANDARD\",\n  \"City\": \"Celje\",\n   \"State\":\"SI\"\n },\n{\n  \"RecordNumber\": 32,\n  \"Zipcode\": 100,\n  \"ZipCodeType\": \"STANDARD\",\n  \"City\": \"Ljubljana\",\n   \"State\":\"SI\", \n   \"Country\":\"Slovenia\",\n   \"Lat\":\"46.0569\",\n   \"Long\":\"14.5058\"\n }]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"82c4803e-ceb6-42af-a263-2bd0f50c6ec1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[46]: [{&#39;RecordNumber&#39;: 2,\n  &#39;Zipcode&#39;: 1000,\n  &#39;ZipCodeType&#39;: &#39;STANDARD&#39;,\n  &#39;City&#39;: &#39;Ljubljana&#39;,\n  &#39;State&#39;: &#39;SI&#39;},\n {&#39;RecordNumber&#39;: 10,\n  &#39;Zipcode&#39;: 3000,\n  &#39;ZipCodeType&#39;: &#39;STANDARD&#39;,\n  &#39;City&#39;: &#39;Celje&#39;,\n  &#39;State&#39;: &#39;SI&#39;},\n {&#39;RecordNumber&#39;: 32,\n  &#39;Zipcode&#39;: 100,\n  &#39;ZipCodeType&#39;: &#39;STANDARD&#39;,\n  &#39;City&#39;: &#39;Ljubljana&#39;,\n  &#39;State&#39;: &#39;SI&#39;,\n  &#39;Country&#39;: &#39;Slovenia&#39;,\n  &#39;Lat&#39;: &#39;46.0569&#39;,\n  &#39;Long&#39;: &#39;14.5058&#39;}]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[46]: [{&#39;RecordNumber&#39;: 2,\n  &#39;Zipcode&#39;: 1000,\n  &#39;ZipCodeType&#39;: &#39;STANDARD&#39;,\n  &#39;City&#39;: &#39;Ljubljana&#39;,\n  &#39;State&#39;: &#39;SI&#39;},\n {&#39;RecordNumber&#39;: 10,\n  &#39;Zipcode&#39;: 3000,\n  &#39;ZipCodeType&#39;: &#39;STANDARD&#39;,\n  &#39;City&#39;: &#39;Celje&#39;,\n  &#39;State&#39;: &#39;SI&#39;},\n {&#39;RecordNumber&#39;: 32,\n  &#39;Zipcode&#39;: 100,\n  &#39;ZipCodeType&#39;: &#39;STANDARD&#39;,\n  &#39;City&#39;: &#39;Ljubljana&#39;,\n  &#39;State&#39;: &#39;SI&#39;,\n  &#39;Country&#39;: &#39;Slovenia&#39;,\n  &#39;Lat&#39;: &#39;46.0569&#39;,\n  &#39;Long&#39;: &#39;14.5058&#39;}]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Read multiline json file\nmultiline_df = spark.read.option(\"multiline\",\"true\") \\\n      .json(\"dbfs:/FileStore/module3/json3.json\")\nmultiline_df.show() "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dd4da30f-98c8-448e-a6c9-52446306658e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+---------+--------+-------+-------+------------+-----+-----------+-------+\n|     City| Country|    Lat|   Long|RecordNumber|State|ZipCodeType|Zipcode|\n+---------+--------+-------+-------+------------+-----+-----------+-------+\n|Ljubljana|    null|   null|   null|           2|   SI|   STANDARD|   1000|\n|    Celje|    null|   null|   null|          10|   SI|   STANDARD|   3000|\n|Ljubljana|Slovenia|46.0569|14.5058|          32|   SI|   STANDARD|    100|\n+---------+--------+-------+-------+------------+-----+-----------+-------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+--------+-------+-------+------------+-----+-----------+-------+\n     City| Country|    Lat|   Long|RecordNumber|State|ZipCodeType|Zipcode|\n+---------+--------+-------+-------+------------+-----+-----------+-------+\nLjubljana|    null|   null|   null|           2|   SI|   STANDARD|   1000|\n    Celje|    null|   null|   null|          10|   SI|   STANDARD|   3000|\nLjubljana|Slovenia|46.0569|14.5058|          32|   SI|   STANDARD|    100|\n+---------+--------+-------+-------+------------+-----+-----------+-------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Now let's read multiple files in this folder"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"032fb06d-b7df-4579-baa1-9431b64dbd55"}}},{"cell_type":"code","source":["# Read multiple files as listed names\ndf = spark.read.option(\"multiline\",\"true\").json(\n    ['dbfs:/FileStore/module3/json3.json','dbfs:/FileStore/module3/json4_corrupt.json'])\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d53ed379-fc96-42be-b194-e409b9828954"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["This is why the files are corrupted. Missing comma and last comma must be removed.\n\n```\n[{\n  \"RecordNumber\": 2,\n  \"Zipcode\": 1000,\n  \"ZipCodeType\": \"STANDARD\",\n  \"City\": \"Ljubljana\",\n   \"State\":\"SI\"\n},\n{\n  \"RecordNumber\": 10,\n  \"Zipcode\": 3000,\n  \"ZipCodeType\": \"STANDARD\",\n  \"City\": \"Celje\",\n   \"State\":\"SI\"\n },\n{\n  \"RecordNumber\": 32,\n  \"Zipcode\": 100,\n  \"ZipCodeType\": \"STANDARD\",\n  \"City\": \"Ljubljana\",\n   \"State\":\"SI\", \n   \"Country\":\"Slovenia\",\n   \"Lat\":\"46.0569\",\n   \"Long\":\"14.5058\"\n }\n{\n  \"RecordNumber\": 104,\n  \"Zipcode\": 89260,\n  \"ZipCodeType\": \"STANDARD\",\n  \"City\": \"Seattle\",\n   \"State\":\"WA\",\n   \"Country\":\"USA\"\n },\n]\n```"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"161b951a-b0b2-47fc-abaa-b7d83b6937a8"}}},{"cell_type":"code","source":["# Read multiple files as listed names and made json5 as corrected copy of json4\ndf = spark.read.option(\"multiline\",\"true\").json(['dbfs:/FileStore/module3/json3.json','dbfs:/FileStore/module3/json5.json'])\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"14f59da9-6f06-42e1-9c71-d8cec02958c9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["df.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bad9e4e9-7964-43ad-bb7e-3e99f12459ee"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+---------+--------+-------+-------+------------+-----+-----------+-------+\n|     City| Country|    Lat|   Long|RecordNumber|State|ZipCodeType|Zipcode|\n+---------+--------+-------+-------+------------+-----+-----------+-------+\n|Ljubljana|    null|   null|   null|           2|   SI|   STANDARD|   1000|\n|    Celje|    null|   null|   null|          10|   SI|   STANDARD|   3000|\n|Ljubljana|Slovenia|46.0569|14.5058|          32|   SI|   STANDARD|    100|\n|  Seattle|     USA|   null|   null|         104|   WA|   STANDARD|  89260|\n|Ljubljana|    null|   null|   null|           2|   SI|   STANDARD|   1000|\n|    Celje|    null|   null|   null|          10|   SI|   STANDARD|   3000|\n|Ljubljana|Slovenia|46.0569|14.5058|          32|   SI|   STANDARD|    100|\n+---------+--------+-------+-------+------------+-----+-----------+-------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+--------+-------+-------+------------+-----+-----------+-------+\n     City| Country|    Lat|   Long|RecordNumber|State|ZipCodeType|Zipcode|\n+---------+--------+-------+-------+------------+-----+-----------+-------+\nLjubljana|    null|   null|   null|           2|   SI|   STANDARD|   1000|\n    Celje|    null|   null|   null|          10|   SI|   STANDARD|   3000|\nLjubljana|Slovenia|46.0569|14.5058|          32|   SI|   STANDARD|    100|\n  Seattle|     USA|   null|   null|         104|   WA|   STANDARD|  89260|\nLjubljana|    null|   null|   null|           2|   SI|   STANDARD|   1000|\n    Celje|    null|   null|   null|          10|   SI|   STANDARD|   3000|\nLjubljana|Slovenia|46.0569|14.5058|          32|   SI|   STANDARD|    100|\n+---------+--------+-------+-------+------------+-----+-----------+-------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Now let's try to read all files from a dedicated folder `dbfs:/FileStore/module3/input_files/`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7813a7e3-674f-4ae7-a19b-9ad4d87064be"}}},{"cell_type":"code","source":["# Read all JSON files from a folder\ndf = spark.read.option(\"multiline\",\"true\").json(\"dbfs:/FileStore/module3/input_files/*.json\")\ndf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1acce9b6-223d-4485-9693-2a1f535dcb13"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+---------+--------+-------+-------+------------+-----+-----------+-------+\n|     City| Country|    Lat|   Long|RecordNumber|State|ZipCodeType|Zipcode|\n+---------+--------+-------+-------+------------+-----+-----------+-------+\n|Ljubljana|Slovenia|46.0569|14.5058|          32|   SI|   STANDARD|    100|\n|  Seattle|     USA|   null|   null|         104|   WA|   STANDARD|  89260|\n|   London|      UK|   null|   null|           2|   LN|   STANDARD|   1000|\n+---------+--------+-------+-------+------------+-----+-----------+-------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+--------+-------+-------+------------+-----+-----------+-------+\n     City| Country|    Lat|   Long|RecordNumber|State|ZipCodeType|Zipcode|\n+---------+--------+-------+-------+------------+-----+-----------+-------+\nLjubljana|Slovenia|46.0569|14.5058|          32|   SI|   STANDARD|    100|\n  Seattle|     USA|   null|   null|         104|   WA|   STANDARD|  89260|\n   London|      UK|   null|   null|           2|   LN|   STANDARD|   1000|\n+---------+--------+-------+-------+------------+-----+-----------+-------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Now let's infer schema. This schema will be user-specified and custom schema."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a82b036e-4b4c-4ef8-aeda-d47ad629224b"}}},{"cell_type":"code","source":["# Define custom schema\nschema = StructType([\n      StructField(\"RecordNumber\",IntegerType(),True),\n      StructField(\"Zipcode\",IntegerType(),True),\n      StructField(\"ZipCodeType\",StringType(),True),\n      StructField(\"City\",StringType(),True),\n      StructField(\"State\",StringType(),True),\n      StructField(\"LocationType\",StringType(),True),\n      StructField(\"Lat\",DoubleType(),True),\n      StructField(\"Long\",DoubleType(),True),\n      StructField(\"WorldRegion\",StringType(),True),\n      StructField(\"Country\",StringType(),True),\n      StructField(\"LocationText\",StringType(),True)\n  ])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ddd4b4ff-1b8a-433a-9776-b26ca8169ee2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["df_with_schema = spark.read.schema(schema) \\\n        .json(\"dbfs:/FileStore/module3/json3.json\")\ndf_with_schema.printSchema()\ndf_with_schema.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d124499b-46d1-4c0c-a6cd-3a518f79dce9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- RecordNumber: integer (nullable = true)\n |-- Zipcode: integer (nullable = true)\n |-- ZipCodeType: string (nullable = true)\n |-- City: string (nullable = true)\n |-- State: string (nullable = true)\n |-- LocationType: string (nullable = true)\n |-- Lat: double (nullable = true)\n |-- Long: double (nullable = true)\n |-- Xaxis: integer (nullable = true)\n |-- Yaxis: double (nullable = true)\n |-- Zaxis: double (nullable = true)\n |-- WorldRegion: string (nullable = true)\n |-- Country: string (nullable = true)\n |-- LocationText: string (nullable = true)\n |-- Location: string (nullable = true)\n |-- Decommisioned: boolean (nullable = true)\n |-- TaxReturnsFiled: string (nullable = true)\n |-- EstimatedPopulation: integer (nullable = true)\n |-- TotalWages: integer (nullable = true)\n |-- Notes: string (nullable = true)\n\n+------------+-------+-----------+----+-----+------------+----+----+-----+-----+-----+-----------+-------+------------+--------+-------------+---------------+-------------------+----------+-----+\n|RecordNumber|Zipcode|ZipCodeType|City|State|LocationType| Lat|Long|Xaxis|Yaxis|Zaxis|WorldRegion|Country|LocationText|Location|Decommisioned|TaxReturnsFiled|EstimatedPopulation|TotalWages|Notes|\n+------------+-------+-----------+----+-----+------------+----+----+-----+-----+-----+-----------+-------+------------+--------+-------------+---------------+-------------------+----------+-----+\n|        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n|        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n|        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n|        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n|        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n|        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n|        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n|        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n|        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n|        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n|        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n|        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n|        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n|        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n|        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n|        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n|        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n|        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n|        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n|        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n+------------+-------+-----------+----+-----+------------+----+----+-----+-----+-----+-----------+-------+------------+--------+-------------+---------------+-------------------+----------+-----+\nonly showing top 20 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- RecordNumber: integer (nullable = true)\n-- Zipcode: integer (nullable = true)\n-- ZipCodeType: string (nullable = true)\n-- City: string (nullable = true)\n-- State: string (nullable = true)\n-- LocationType: string (nullable = true)\n-- Lat: double (nullable = true)\n-- Long: double (nullable = true)\n-- Xaxis: integer (nullable = true)\n-- Yaxis: double (nullable = true)\n-- Zaxis: double (nullable = true)\n-- WorldRegion: string (nullable = true)\n-- Country: string (nullable = true)\n-- LocationText: string (nullable = true)\n-- Location: string (nullable = true)\n-- Decommisioned: boolean (nullable = true)\n-- TaxReturnsFiled: string (nullable = true)\n-- EstimatedPopulation: integer (nullable = true)\n-- TotalWages: integer (nullable = true)\n-- Notes: string (nullable = true)\n\n+------------+-------+-----------+----+-----+------------+----+----+-----+-----+-----+-----------+-------+------------+--------+-------------+---------------+-------------------+----------+-----+\nRecordNumber|Zipcode|ZipCodeType|City|State|LocationType| Lat|Long|Xaxis|Yaxis|Zaxis|WorldRegion|Country|LocationText|Location|Decommisioned|TaxReturnsFiled|EstimatedPopulation|TotalWages|Notes|\n+------------+-------+-----------+----+-----+------------+----+----+-----+-----+-----+-----------+-------+------------+--------+-------------+---------------+-------------------+----------+-----+\n        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n        null|   null|       null|null| null|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n+------------+-------+-----------+----+-----+------------+----+----+-----+-----+-----+-----------+-------+------------+--------+-------------+---------------+-------------------+----------+-----+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Reading JSON files using Spark SQL"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d99fca61-0b1c-4123-bbcc-31baf01b4dca"}}},{"cell_type":"code","source":["\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import StructType,StructField, StringType, IntegerType,BooleanType,DoubleType\nspark = SparkSession.builder \\\n    .master(\"local[1]\") \\\n    .appName(\"module3\") \\\n    .getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"573c2b83-4623-49cd-a586-3a86f28dad77"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Create a table from Parquet File\nspark.sql(\"CREATE OR REPLACE TEMPORARY VIEW json3 USING json OPTIONS (path 'dbfs:/FileStore/module3/json3.json')\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"358dc5f4-62f2-44cf-8fc5-c0393a51de95"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[85]: DataFrame[]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[85]: DataFrame[]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["df2 = spark.sql(\"select * from json3\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"885011c6-769a-4f07-a76d-e60f43dd6f27"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# PySpark write Parquet File\n# referring to dataframe called df!\ndf.write.mode('Overwrite').json(\"dbfs:/FileStore/module3/output/res.json\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"87b4d780-b986-4d31-a0f4-7892506beb4f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Getting data from Source"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ca02dae2-0599-4606-a804-cdd7837e50df"}}},{"cell_type":"markdown","source":["Covered in Module 2"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4e729399-6355-4644-9a5a-5a51325c3330"}}},{"cell_type":"markdown","source":["## Moving Data Around"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4c4dc7a9-76f6-4716-a85c-395ab425535f"}}},{"cell_type":"markdown","source":["### Using fs"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"126ad81c-d579-406f-9761-f13d7f957d75"}}},{"cell_type":"code","source":["# Default location for %fs is root\n# Creating fol\n%fs ls /tmp/\n%fs mkdirs /tmp/my_cloud_dir\n%fs cp /tmp/test_dbfs.txt /tmp/file_b.txt"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f522f6a5-f2a9-4b44-8442-71f7176473e7"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# locate folder\n# mount data\n# read data\nimport os \nos.listdir('/dbfs/tmp')\ndbutils.fs.ls(\"/mnt/mymount\") \ndf = spark.read.text(\"dbfs:/mymount/my_file.txt\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b4d20ea7-7aa9-4b55-84e3-f14ddb85dded"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%scala\n\nimport scala.sys.process._\n\n// Write a file using the local file API (over the FUSE mount).\ndbutils.fs.put(\"file:/dbfs/tmp/test\", \"test-contents\")\n\n// Flush to persistent storage.\n\"sync /dbfs/tmp/test\" !\n\n// Read the file using \"dbfs:/\" instead of the FUSE mount.\ndbutils.fs.head(\"dbfs:/tmp/test\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f7f58081-af37-4b63-aed0-c1510b312b9c"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Working with SQL"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"03753c18-21a0-4a0e-a044-41dd87ab3fae"}}},{"cell_type":"code","source":["%scala\n\nimport org.apache.spark.sql.SparkSession\n\nval username = System.getProperty(\"user.name\")\nval spark = SparkSession.\n    builder.\n    config(\"spark.ui.port\", \"0\").\n    config(\"spark.sql.warehouse.dir\", s\"/user/${username}/warehouse\").\n    enableHiveSupport.\n    appName(s\"${username} | Spark SQL - Basic Transformations\").\n    master(\"yarn\").\n    getOrCreate"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c5c80d34-bbc4-4272-ada2-77509c44b564"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["General commands with scala"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"480a91e3-5794-4715-9201-6720a7badd3e"}}},{"cell_type":"code","source":["%sql\nDROP DATABASE SQLBits2022 CASCADE\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ff8b823c-9514-4466-9f75-96ac9ef264ab"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"com.databricks.backend.common.rpc.DatabricksExceptions$SQLExecutionException: org.apache.spark.sql.AnalysisException: org.apache.hadoop.hive.metastore.api.NoSuchObjectException: There is no database named sqlbits2022\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$withClient$2(HiveExternalCatalog.scala:161)\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.maybeSynchronized(HiveExternalCatalog.scala:112)\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$withClient$1(HiveExternalCatalog.scala:150)\n\tat com.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:377)\n\tat com.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:363)\n\tat com.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:149)\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.dropDatabase(HiveExternalCatalog.scala:275)\n\tat org.apache.spark.sql.catalyst.catalog.ExternalCatalogWithListener.dropDatabase(ExternalCatalogWithListener.scala:61)\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalogImpl.dropDatabase(SessionCatalog.scala:621)\n\tat com.databricks.sql.managedcatalog.ManagedCatalogSessionCatalog.dropDatabase(ManagedCatalogSessionCatalog.scala:306)\n\tat org.apache.spark.sql.execution.command.DropDatabaseCommand.run(ddl.scala:114)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:235)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3825)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:130)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:273)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:104)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:854)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:77)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:223)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3823)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:235)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:104)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:854)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:101)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:689)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:854)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:684)\n\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:694)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.$anonfun$executeSql$1(SQLDriverLocal.scala:91)\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\n\tat scala.collection.immutable.List.map(List.scala:298)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:37)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:145)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$11(DriverLocal.scala:526)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:266)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:261)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:258)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:50)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:305)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:297)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:50)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:503)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:689)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:681)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:522)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:634)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:427)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:370)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:221)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: NoSuchObjectException(message:There is no database named sqlbits2022)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.getMDatabase(ObjectStore.java:487)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.getDatabase(ObjectStore.java:498)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:108)\n\tat com.sun.proxy.$Proxy57.getDatabase(Unknown Source)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_database(HiveMetaStore.java:796)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:105)\n\tat com.sun.proxy.$Proxy58.get_database(Unknown Source)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getDatabase(HiveMetaStoreClient.java:949)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:608)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:89)\n\tat com.sun.proxy.$Proxy59.dropDatabase(Unknown Source)\n\tat org.apache.hadoop.hive.ql.metadata.Hive.dropDatabase(Hive.java:299)\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$dropDatabase$1(HiveClientImpl.scala:398)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:348)\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$retryLocked$1(HiveClientImpl.scala:251)\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.synchronizeOnObject(HiveClientImpl.scala:287)\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:243)\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:330)\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.dropDatabase(HiveClientImpl.scala:398)\n\tat org.apache.spark.sql.hive.client.PoolingHiveClient.$anonfun$dropDatabase$1(PoolingHiveClient.scala:365)\n\tat org.apache.spark.sql.hive.client.PoolingHiveClient.$anonfun$dropDatabase$1$adapted(PoolingHiveClient.scala:365)\n\tat org.apache.spark.sql.hive.client.PoolingHiveClient.withHiveClient(PoolingHiveClient.scala:145)\n\tat org.apache.spark.sql.hive.client.PoolingHiveClient.dropDatabase(PoolingHiveClient.scala:365)\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$dropDatabase$1(HiveExternalCatalog.scala:275)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$withClient$2(HiveExternalCatalog.scala:151)\n\t... 58 more\n\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:130)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:145)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$11(DriverLocal.scala:526)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:266)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:261)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:258)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:50)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:305)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:297)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:50)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:503)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:689)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:681)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:522)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:634)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:427)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:370)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:221)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorSummary":"Error in SQL statement: AnalysisException: org.apache.hadoop.hive.metastore.api.NoSuchObjectException: There is no database named sqlbits2022","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\ncom.databricks.backend.common.rpc.DatabricksExceptions$SQLExecutionException: org.apache.spark.sql.AnalysisException: org.apache.hadoop.hive.metastore.api.NoSuchObjectException: There is no database named sqlbits2022\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$withClient$2(HiveExternalCatalog.scala:161)\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.maybeSynchronized(HiveExternalCatalog.scala:112)\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$withClient$1(HiveExternalCatalog.scala:150)\n\tat com.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:377)\n\tat com.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:363)\n\tat com.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:149)\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.dropDatabase(HiveExternalCatalog.scala:275)\n\tat org.apache.spark.sql.catalyst.catalog.ExternalCatalogWithListener.dropDatabase(ExternalCatalogWithListener.scala:61)\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalogImpl.dropDatabase(SessionCatalog.scala:621)\n\tat com.databricks.sql.managedcatalog.ManagedCatalogSessionCatalog.dropDatabase(ManagedCatalogSessionCatalog.scala:306)\n\tat org.apache.spark.sql.execution.command.DropDatabaseCommand.run(ddl.scala:114)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:235)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3825)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:130)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:273)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:104)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:854)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:77)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:223)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3823)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:235)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:104)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:854)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:101)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:689)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:854)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:684)\n\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:694)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.$anonfun$executeSql$1(SQLDriverLocal.scala:91)\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\n\tat scala.collection.immutable.List.map(List.scala:298)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:37)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:145)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$11(DriverLocal.scala:526)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:266)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:261)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:258)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:50)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:305)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:297)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:50)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:503)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:689)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:681)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:522)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:634)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:427)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:370)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:221)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: NoSuchObjectException(message:There is no database named sqlbits2022)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.getMDatabase(ObjectStore.java:487)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.getDatabase(ObjectStore.java:498)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:108)\n\tat com.sun.proxy.$Proxy57.getDatabase(Unknown Source)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_database(HiveMetaStore.java:796)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:105)\n\tat com.sun.proxy.$Proxy58.get_database(Unknown Source)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getDatabase(HiveMetaStoreClient.java:949)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:608)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:89)\n\tat com.sun.proxy.$Proxy59.dropDatabase(Unknown Source)\n\tat org.apache.hadoop.hive.ql.metadata.Hive.dropDatabase(Hive.java:299)\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$dropDatabase$1(HiveClientImpl.scala:398)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:348)\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$retryLocked$1(HiveClientImpl.scala:251)\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.synchronizeOnObject(HiveClientImpl.scala:287)\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:243)\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:330)\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.dropDatabase(HiveClientImpl.scala:398)\n\tat org.apache.spark.sql.hive.client.PoolingHiveClient.$anonfun$dropDatabase$1(PoolingHiveClient.scala:365)\n\tat org.apache.spark.sql.hive.client.PoolingHiveClient.$anonfun$dropDatabase$1$adapted(PoolingHiveClient.scala:365)\n\tat org.apache.spark.sql.hive.client.PoolingHiveClient.withHiveClient(PoolingHiveClient.scala:145)\n\tat org.apache.spark.sql.hive.client.PoolingHiveClient.dropDatabase(PoolingHiveClient.scala:365)\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$dropDatabase$1(HiveExternalCatalog.scala:275)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$withClient$2(HiveExternalCatalog.scala:151)\n\t... 58 more\n\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:130)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:145)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$11(DriverLocal.scala:526)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:266)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:261)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:258)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:50)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:305)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:297)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:50)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:503)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:689)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:681)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:522)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:634)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:427)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:370)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:221)\n\tat java.lang.Thread.run(Thread.java:748)"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\nCREATE DATABASE IF NOT EXISTS SQLBits2022"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d7e505b6-f7ea-45b6-9415-ca1306e91ca0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\nUSE SQLBits2022"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a8690dba-044d-40dc-bd80-a3d112728400"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\nSHOW tables"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3f72f70e-4dbf-4345-9850-1b0fdf8a289c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"database","type":"\"string\"","metadata":"{}"},{"name":"tableName","type":"\"string\"","metadata":"{}"},{"name":"isTemporary","type":"\"boolean\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>database</th><th>tableName</th><th>isTemporary</th></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\n\nDROP TABLE SQLUsers"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9f3530c1-73b7-40ae-a870-47001b44843f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\n\nCREATE TABLE SQLUsers (\n    User_ID INT,\n    User_Name STRING,\n    Registration_date STRING,\n    User_age INT,\n    COVID_Status STRING,\n    Country STRING\n) ROW FORMAT DELIMITED FIELDS TERMINATED BY ','"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"be23aca6-fde4-4bb5-9d39-49663a9c584b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\nSHOW tables"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"188675af-7907-4690-a567-57b6eb5155c7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["sqlbits2022","sqlusers",false]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"database","type":"\"string\"","metadata":"{}"},{"name":"tableName","type":"\"string\"","metadata":"{}"},{"name":"isTemporary","type":"\"boolean\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>database</th><th>tableName</th><th>isTemporary</th></tr></thead><tbody><tr><td>sqlbits2022</td><td>sqlusers</td><td>false</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["\n%sql\n-- fake Data :)\n\nINSERT INTO SQLUsers VALUES\n        (232, 'Stijn Wynants', '2021-12-20', 28, 'ok', 'BE'),\n        (241, 'Terry and Simon', '2021-11-23', 33, 'ok', 'UK'),\n        (22, 'Steve Jones', '2022-01-02', 43, 'ok', 'USA'), \n        (42, 'Cathrine Wilhelmsen', '2021-11-24', 33, 'ok', 'NO'),\n        (52, 'Prathy Kamasani', '2021-12-03', 33, 'ok', 'UK');"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"432cf52b-e093-439c-b80d-420e27452f61"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\n\nSELECT * FROM SQLUsers"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5dd89c8a-a5c9-4c37-aeb1-51d4949f8e03"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[232,"Stijn Wynants","2021-12-20",28,"ok"],[241,"Terry and Simon","2021-11-23",33,"ok"],[22,"Steve Jones","2022-01-02",43,"ok"],[42,"Cathrine Wilhelmsen","2021-11-24",33,"ok"],[52,"Prathy Kamasani","2021-12-03",33,"ok"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"User_ID","type":"\"integer\"","metadata":"{}"},{"name":"User_Name","type":"\"string\"","metadata":"{}"},{"name":"Registration_date","type":"\"string\"","metadata":"{}"},{"name":"User_age","type":"\"integer\"","metadata":"{}"},{"name":"COVID_Status","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>User_ID</th><th>User_Name</th><th>Registration_date</th><th>User_age</th><th>COVID_Status</th></tr></thead><tbody><tr><td>232</td><td>Stijn Wynants</td><td>2021-12-20</td><td>28</td><td>ok</td></tr><tr><td>241</td><td>Terry and Simon</td><td>2021-11-23</td><td>33</td><td>ok</td></tr><tr><td>22</td><td>Steve Jones</td><td>2022-01-02</td><td>43</td><td>ok</td></tr><tr><td>42</td><td>Cathrine Wilhelmsen</td><td>2021-11-24</td><td>33</td><td>ok</td></tr><tr><td>52</td><td>Prathy Kamasani</td><td>2021-12-03</td><td>33</td><td>ok</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\n-- overwrite complete table!\nINSERT OVERWRITE SQLUsers VALUES\n(232, 'Stijn Wynants', '2021-12-20', 31, 'ok', 'BE');\n-- !!! MAke Sure to populate the table :) Thanks"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aff8a116-cbf2-48d6-bc64-df761e89e921"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\nSELECT * FROM SQLUsers"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e63039ae-7d83-4209-b6fc-f1dfed3744c9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[232,"Stijn Wynants","2021-12-20",31,"ok"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"User_ID","type":"\"integer\"","metadata":"{}"},{"name":"User_Name","type":"\"string\"","metadata":"{}"},{"name":"Registration_date","type":"\"string\"","metadata":"{}"},{"name":"User_age","type":"\"integer\"","metadata":"{}"},{"name":"COVID_Status","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>User_ID</th><th>User_Name</th><th>Registration_date</th><th>User_age</th><th>COVID_Status</th></tr></thead><tbody><tr><td>232</td><td>Stijn Wynants</td><td>2021-12-20</td><td>31</td><td>ok</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sql \n-- importing directly into table\n\nCREATE TABLE People_parquet (\n  Age STRING,\n  Name STRING\n) USING parquet\nOPTIONS (\n  `parquet.bloom.filter.enabled#favorite_color` true,\n  `parquet.bloom.filter.expected.ndv#favorite_color` 1000000,\n  `parquet.enable.dictionary` true,\n  `parquet.page.write-checksum.enabled` true\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"01ecd8f4-c080-4655-92ec-e808ed3d4f8f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"com.databricks.backend.common.rpc.DatabricksExceptions$SQLExecutionException: org.apache.spark.sql.AnalysisException: Table sqlbits2022.People_parquet already exists.\n\tat org.apache.spark.sql.execution.command.CreateDataSourceTableCommand.run(createDataSourceTables.scala:67)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:235)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3825)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:130)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:273)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:104)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:854)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:77)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:223)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3823)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:235)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:104)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:854)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:101)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:689)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:854)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:684)\n\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:694)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.$anonfun$executeSql$1(SQLDriverLocal.scala:91)\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\n\tat scala.collection.immutable.List.map(List.scala:298)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:37)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:145)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$11(DriverLocal.scala:526)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:266)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:261)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:258)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:50)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:305)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:297)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:50)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:503)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:689)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:681)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:522)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:634)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:427)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:370)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:221)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:130)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:145)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$11(DriverLocal.scala:526)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:266)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:261)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:258)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:50)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:305)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:297)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:50)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:503)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:689)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:681)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:522)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:634)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:427)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:370)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:221)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorSummary":"Error in SQL statement: AnalysisException: Table sqlbits2022.People_parquet already exists.","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\ncom.databricks.backend.common.rpc.DatabricksExceptions$SQLExecutionException: org.apache.spark.sql.AnalysisException: Table sqlbits2022.People_parquet already exists.\n\tat org.apache.spark.sql.execution.command.CreateDataSourceTableCommand.run(createDataSourceTables.scala:67)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:235)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3825)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:130)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:273)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:104)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:854)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:77)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:223)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3823)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:235)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:104)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:854)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:101)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:689)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:854)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:684)\n\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:694)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.$anonfun$executeSql$1(SQLDriverLocal.scala:91)\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\n\tat scala.collection.immutable.List.map(List.scala:298)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:37)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:145)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$11(DriverLocal.scala:526)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:266)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:261)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:258)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:50)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:305)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:297)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:50)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:503)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:689)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:681)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:522)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:634)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:427)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:370)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:221)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:130)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:145)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$11(DriverLocal.scala:526)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:266)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:261)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:258)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:50)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:305)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:297)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:50)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:503)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:689)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:681)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:522)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:634)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:427)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:370)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:221)\n\tat java.lang.Thread.run(Thread.java:748)"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\nSELECT * FROM People_parquet"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"44b4ae60-75c6-451b-857c-25dbbb46f7dd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"Age","type":"\"string\"","metadata":"{}"},{"name":"Name","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Age</th><th>Name</th></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\n\nCREATE TEMPORARY VIEW parquetTable\nUSING org.apache.spark.sql.parquet\nOPTIONS (\n  path \"dbfs:/people.parquet\"\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"13423989-fa73-4e8c-9870-327b10dfd22c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\nSELECT * FROM parquetTable"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0318895d-8f2c-413f-bf9f-ecba1d26dbd0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[null,"Michael"],[30,"Andy"],[19,"Justin"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"age","type":"\"long\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>age</th><th>name</th></tr></thead><tbody><tr><td>null</td><td>Michael</td></tr><tr><td>30</td><td>Andy</td></tr><tr><td>19</td><td>Justin</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\nINSERT INTO People_parquet\nSELECT * FROM parquetTable "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"83f27b51-4a05-4cf2-8c8f-cafae42f9771"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\nSELECT * FROM People_parquet\n-- Check database for new tables! temp view: parquetTable should not be there! only: People_parquet"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"88715e23-fcc1-41aa-9a7d-49744e3cb3ba"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[null,"Michael"],["30","Andy"],["19","Justin"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"Age","type":"\"string\"","metadata":"{}"},{"name":"Name","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Age</th><th>Name</th></tr></thead><tbody><tr><td>null</td><td>Michael</td></tr><tr><td>30</td><td>Andy</td></tr><tr><td>19</td><td>Justin</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#for comparison\ndf = spark.sql(\"SELECT * FROM parquet.`dbfs:/people.parquet`\")\ndf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"74a69436-201b-418c-8464-daba24643e67"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["###  Spark SQL functions (count, countDistinct, Max, Min, Sum, SumDistinct, AVG)\n###  Spark SQL statemetns, operations, WHERE"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d5d73c76-f2e4-4761-b00d-e9b302a50b94"}}},{"cell_type":"code","source":["%sql\n\nSELECT * FROM SQLUsers\n-- WHERE Country IN ('UK', 'NO') LIMIT 2\n-- WHERE Country NOT IN ('SI', 'BE')\n-- WHERE Registration_date >= '2021-12-03'\n-- WHERE YEAR(Registration_date) = 2022\n-- WHERE USER_ID between 200 AND 250\nWHERE User_name Like '%an%'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"96241f60-48a9-4392-b2f2-c5d72f6e97c4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[232,"Stijn Wynants","2021-12-20",28,"ok","BE"],[232,"Stijn Wynants","2021-12-20",31,"ok","BE"],[241,"Terry and Simon","2021-11-23",33,"ok","UK"],[52,"Prathy Kamasani","2021-12-03",33,"ok","UK"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"User_ID","type":"\"integer\"","metadata":"{}"},{"name":"User_Name","type":"\"string\"","metadata":"{}"},{"name":"Registration_date","type":"\"string\"","metadata":"{}"},{"name":"User_age","type":"\"integer\"","metadata":"{}"},{"name":"COVID_Status","type":"\"string\"","metadata":"{}"},{"name":"Country","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>User_ID</th><th>User_Name</th><th>Registration_date</th><th>User_age</th><th>COVID_Status</th><th>Country</th></tr></thead><tbody><tr><td>232</td><td>Stijn Wynants</td><td>2021-12-20</td><td>28</td><td>ok</td><td>BE</td></tr><tr><td>232</td><td>Stijn Wynants</td><td>2021-12-20</td><td>31</td><td>ok</td><td>BE</td></tr><tr><td>241</td><td>Terry and Simon</td><td>2021-11-23</td><td>33</td><td>ok</td><td>UK</td></tr><tr><td>52</td><td>Prathy Kamasani</td><td>2021-12-03</td><td>33</td><td>ok</td><td>UK</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\n\n-- SELECT COUNT(*) as nof_all FROM SQLUsers\n-- SELECT DISTINCT(User_ID) as nof_all_distinct FROM SQLUsers\n-- SELECT countDistinct(User_ID) as nof_all_distinct FROM SQLUsers -- Nope\n-- SELECT COUNT(DISTINCT(User_ID)) as nof_all_distinct FROM SQLUsers \n-- SELECT MAX(User_age), MIN(User_age), AVG(User_age) FROM SQLUsers\n-- SELECT COUNT(DISTINCT(User_ID)) AS totalALL, Country FROM SQLUsers GROUP BY Country ORDER BY Country\n-- SELECT SUM(CASE WHEN Country = 'UK' AND User_NAme like '%erry and Si%'THEN 2 ELSE 1 END) as NofPeople ,Country FROM SQLUSers GROUP BY Country"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"74e33b15-099d-4737-a48f-a0227c35301b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[2,"BE"],[1,"USA"],[3,"UK"],[1,"NO"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"NofPeople","type":"\"long\"","metadata":"{}"},{"name":"Country","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>NofPeople</th><th>Country</th></tr></thead><tbody><tr><td>2</td><td>BE</td></tr><tr><td>1</td><td>USA</td></tr><tr><td>3</td><td>UK</td></tr><tr><td>1</td><td>NO</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\n\n-- using distinct not to get cartesian product\nSELECT DISTINCT\n   tab1.User_id\n  ,tab1.User_Name \n  ,tab2.Country\n FROM SQLUsers AS tab1\nINNER JOIN SQLUsers AS tab2\nON tab1.user_id = tab2.user_id\n-- Check Data Profile, DAG, Query plan"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ec0db723-ab79-40e4-977e-deedd6a396aa"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[22,"Steve Jones","USA"],[42,"Cathrine Wilhelmsen","NO"],[52,"Prathy Kamasani","UK"],[232,"Stijn Wynants","BE"],[241,"Terry and Simon","UK"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"User_id","type":"\"integer\"","metadata":"{}"},{"name":"User_Name","type":"\"string\"","metadata":"{}"},{"name":"Country","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>User_id</th><th>User_Name</th><th>Country</th></tr></thead><tbody><tr><td>22</td><td>Steve Jones</td><td>USA</td></tr><tr><td>42</td><td>Cathrine Wilhelmsen</td><td>NO</td></tr><tr><td>52</td><td>Prathy Kamasani</td><td>UK</td></tr><tr><td>232</td><td>Stijn Wynants</td><td>BE</td></tr><tr><td>241</td><td>Terry and Simon</td><td>UK</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["By using Spark functions, we get much more statistical and mathematical functions"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"59e12393-882d-49cd-8cad-1c561d28b360"}}},{"cell_type":"markdown","source":["Table partitioning using Hive with Parquet"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d7153b97-f5df-49d8-a2cc-521d054281ef"}}},{"cell_type":"code","source":["%sql\n-- Create table with partitions\nCREATE TABLE SQLUsers_partitioned (\n    User_ID INT,\n    User_Name STRING,\n    Registration_date STRING,\n    User_age INT,\n    COVID_Status STRING,\n    Country STRING\n) PARTITIONED BY (Month_registered STRING)\nROW FORMAT DELIMITED FIELDS TERMINATED BY ','\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"714580c7-d549-4aac-bacd-a00a03de39d9"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n-- adding partitions\n \nALTER TABLE SQLUsers_partitioned ADD PARTITION (Month_registered='2022-04')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"476eab30-3fba-4265-ad50-cb82de87c399"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Adding new partitions for upcoming months\n\nALTER TABLE SQLUsers_partitioned ADD\n    PARTITION (Month_registered='2022-05')\n    PARTITION (Month_registered='2022-06')\n    PARTITION (Month_registered='2022-07')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cc17e6a2-66f5-471d-8938-2e6e1c8b542d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n-- inserting into partitions\n\nINSERT INTO TABLE SQLUsers_partitioned PARTITION (Month_registered='2022-05')\n  SELECT * FROM SQLUsers WHERE Registration_date LIKE '%2022-05%'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fc706a88-2ba3-4d8e-97d4-92c98998e778"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Inserting from CLI \n// Pseudo code\n```\nrm -rf ~/registrations\nmkdir -p ~/registrations\n\ngrep 2022-05 /Raw_zone/SQLBitsData/registrations/part-00000 > ~/registrations/Registrations_2022_05\ngrep 2022-06 /Raw_zone/SQLBitsData/registrations/part-00000 > ~/registrations/Registrations_2022_06\ngrep 2022-07 /Raw_zone/SQLBitsData/registrations/part-00000 > ~/registrations/Registrations_2022_07\n```"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"41aeb8d8-6d39-401e-8085-ee78231bc832"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Py3-Module3 - Part 2","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":1667124601533689}},"nbformat":4,"nbformat_minor":0}
