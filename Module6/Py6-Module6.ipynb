{"cells":[{"cell_type":"markdown","source":["# Module 6"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ddc88d90-c1cc-44c6-91b5-28e6512cbd61"}}},{"cell_type":"markdown","source":["## Performance test: Scala vs. Python"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3c422614-f57c-4015-ad56-31caf5387757"}}},{"cell_type":"code","source":["# create a random txt file\nfrom random import sample\n# install nltk package\nfrom nltk.corpus import words\nimport nltk"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4becf425-0135-45da-ab46-1c5906c84cc0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ModuleNotFoundError</span>                       Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3081098189123301&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\"># create a random txt file</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> <span class=\"ansi-green-fg\">from</span> random <span class=\"ansi-green-fg\">import</span> sample\n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\"> </span><span class=\"ansi-green-fg\">from</span> nltk<span class=\"ansi-blue-fg\">.</span>corpus <span class=\"ansi-green-fg\">import</span> words\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> <span class=\"ansi-green-fg\">import</span> nltk\n\n<span class=\"ansi-green-fg\">/databricks/python_shell/dbruntime/PythonPackageImportsInstrumentation/__init__.py</span> in <span class=\"ansi-cyan-fg\">import_patch</span><span class=\"ansi-blue-fg\">(name, globals, locals, fromlist, level)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    156</span>             <span class=\"ansi-red-fg\"># Import the desired module. If you’re seeing this while debugging a failed import,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    157</span>             <span class=\"ansi-red-fg\"># look at preceding stack frames for relevant error information.</span>\n<span class=\"ansi-green-fg\">--&gt; 158</span><span class=\"ansi-red-fg\">             </span>original_result <span class=\"ansi-blue-fg\">=</span> python_builtin_import<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">,</span> globals<span class=\"ansi-blue-fg\">,</span> locals<span class=\"ansi-blue-fg\">,</span> fromlist<span class=\"ansi-blue-fg\">,</span> level<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    159</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    160</span>             is_root_import <span class=\"ansi-blue-fg\">=</span> thread_local<span class=\"ansi-blue-fg\">.</span>_nest_level <span class=\"ansi-blue-fg\">==</span> <span class=\"ansi-cyan-fg\">1</span>\n\n<span class=\"ansi-red-fg\">ModuleNotFoundError</span>: No module named &#39;nltk&#39;</div>","errorSummary":"<span class=\"ansi-red-fg\">ModuleNotFoundError</span>: No module named &#39;nltk&#39;","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ModuleNotFoundError</span>                       Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3081098189123301&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\"># create a random txt file</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> <span class=\"ansi-green-fg\">from</span> random <span class=\"ansi-green-fg\">import</span> sample\n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\"> </span><span class=\"ansi-green-fg\">from</span> nltk<span class=\"ansi-blue-fg\">.</span>corpus <span class=\"ansi-green-fg\">import</span> words\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> <span class=\"ansi-green-fg\">import</span> nltk\n\n<span class=\"ansi-green-fg\">/databricks/python_shell/dbruntime/PythonPackageImportsInstrumentation/__init__.py</span> in <span class=\"ansi-cyan-fg\">import_patch</span><span class=\"ansi-blue-fg\">(name, globals, locals, fromlist, level)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    156</span>             <span class=\"ansi-red-fg\"># Import the desired module. If you’re seeing this while debugging a failed import,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    157</span>             <span class=\"ansi-red-fg\"># look at preceding stack frames for relevant error information.</span>\n<span class=\"ansi-green-fg\">--&gt; 158</span><span class=\"ansi-red-fg\">             </span>original_result <span class=\"ansi-blue-fg\">=</span> python_builtin_import<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">,</span> globals<span class=\"ansi-blue-fg\">,</span> locals<span class=\"ansi-blue-fg\">,</span> fromlist<span class=\"ansi-blue-fg\">,</span> level<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    159</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    160</span>             is_root_import <span class=\"ansi-blue-fg\">=</span> thread_local<span class=\"ansi-blue-fg\">.</span>_nest_level <span class=\"ansi-blue-fg\">==</span> <span class=\"ansi-cyan-fg\">1</span>\n\n<span class=\"ansi-red-fg\">ModuleNotFoundError</span>: No module named &#39;nltk&#39;</div>"]}}],"execution_count":0},{"cell_type":"code","source":["nltk.download('words')\nn = 1000\np = 300\nwith open(\"dbts:/FileStore/module6/random_text.txt\", \"w+\") as file:\n    for i in range(n):\n        ligne  = \" \".join(sample(words.words(), p))\n        file.write(ligne)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"851e2e54-ebbd-4797-9f04-3cd1cc94139b"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Run the tests: PySpark vs. Scala"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0c262dc9-5163-4d86-8193-c49e5932f38d"}}},{"cell_type":"code","source":["from pyspark import SparkConf, SparkContext\nimport time\n\n\nstart_time = time.time()\n\n#conf = SparkConf().setAppName(\"Spark Performance Word Count\")\n#sc = SparkContext(conf=conf)\ntext_file = sc.textFile(r\"dbfs:/FileStore/module6/random_text.txt\")\n\ncounts = text_file.flatMap(lambda line: line.split(\" \")) \\\n             .map(lambda word: (word, 1)) \\\n             .reduceByKey(lambda a, b: a + b)\\\n             .sortBy(lambda a: a[1],ascending=False)\ncounts.saveAsTextFile(r\"dbfs:/FileStore/module6/output_python\")\n\nprint( \"Elapsed Time in mili seconds: \" , (time.time() - start_time)*1000)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1e29ae34-8ad9-4f7c-afe4-cce810c51649"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Elapsed Time in mili seconds:  13747.186660766602\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Elapsed Time in mili seconds:  13747.186660766602\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%scala\n\nval start1: Long = System.currentTimeMillis\nval text_file = sc.parallelize(Array(\"dbfs:/FileStore/module6/random_text.txt\"))\nval count  = text_file.flatMap(line => line.split(\" \"))\n                                        .map(word  => (word, 1))\n                                        .reduceByKey(_+_)\n                                        .sortBy(_._2)\n\n\ncount.saveAsTextFile(\"dbfs:/FileStore/module6/output_scala2\")\n\nval end1: Long = System.currentTimeMillis\nSystem.out.println(\"Elapsed Time in mili seconds: \" + (end1 - start1))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"585ee033-d34f-43d3-9a18-db1e201f8784"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Elapsed Time in mili seconds: 845\nstart1: Long = 1646595471377\ntext_file: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[39] at parallelize at command-3081098189123344:3\ncount: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[47] at sortBy at command-3081098189123344:7\nend1: Long = 1646595472222\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Elapsed Time in mili seconds: 845\nstart1: Long = 1646595471377\ntext_file: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[39] at parallelize at command-3081098189123344:3\ncount: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[47] at sortBy at command-3081098189123344:7\nend1: Long = 1646595472222\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Results\n\n| PySpark | Scala |\n| --- | --- |\n|Elapsed Time in mili seconds:  **13747.186660766602** | Elapsed Time in mili seconds: **845** |"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"269587e5-3390-4c67-9eda-48716e565b0b"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Py6-Module6","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3081098189123297}},"nbformat":4,"nbformat_minor":0}
